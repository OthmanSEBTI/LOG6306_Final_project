sha,message,html_url,repository_id,repository_full_name,repository_private,repository_fork
3c1d4b841d33d0b6e90ca676d9bf4a1402354b91,"Do not use superconsole::State in TimedList//Summary:/`TimedList` component now grabs `&SuperConsoleState` in constructor instead of fetching it from the state.//So `TimedList` is statically typed now. No more errors because code compiles but does not work because forgot to put something in the state.//Code is a bit rough, `SuperConsoleState` is too much for `TimedList`. Can be cleaned up later, even as is I consider this version a big improvement.//Next step would be:/* use this pattern everywhere else in buck2/* remove `State` from `superconsole` and recommend this pattern as default/* similarly we can remove `DrawMode` from `superconsole`//Reviewed By: bobyangyf//Differential Revision: D44814677//fbshipit-source-id: c7a0ca14c71bff9c226cd13a49156cbb44cc7ae9",https://github.com/facebook/buck2/commit/3c1d4b841d33d0b6e90ca676d9bf4a1402354b91,450625045,facebook/buck2,False,False
72c71c007e7bdf667e3fe69bf7dc3a87ae44c0ac,"fixing deploy script//to conform to new [envvar pattern](https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/), fixes #851 upstream",https://github.com/facebook/Rapid/commit/72c71c007e7bdf667e3fe69bf7dc3a87ae44c0ac,161120445,facebook/Rapid,False,False
2a34c5b8edb70315fe2c7ef63faefcb9359d2c63,"fby35: cl: revise PMIC error VinB_UV pattern (#1009)//Summary:/Revise PMIC error VinB_UV pattern.//Pull Request resolved: https://github.com/facebook/OpenBIC/pull/1009//Test Plan:/Build and test pass on fby35 system./1. Inject VinB_UV and check SEL root@bmc-oob:~# log-util all --print/2023 Mar 27 01:57:34 log-util: User cleared all logs/2    slot2    2023-03-27 01:57:53    ipmid            SEL Entry: FRU: 2, Record: Standard (0x02), Time: 2023-03-27 01:57:53, Sensor: PMIC_ERR (0xB4), Event Data: (050A00) DIMM A7 Vin Bulk UV Assertion/2    slot2    2023-03-27 01:57:56    gpiod            FRU: 2, System powered OFF/2    slot2    2023-03-27 01:57:58    ipmid            SEL Entry: FRU: 2, Record: Standard (0x02), Time: 2023-03-27 01:57:58, Sensor: ME_POWER_STATE (0x16), Event Data: (000000) RUNNING Assertion//Reviewed By: williamspatrick, tao-ren//Differential Revision: D44477822//Pulled By: amithash//fbshipit-source-id: a0f71027f518b42aa0de7b20f5b88f50381eb20a",https://github.com/facebook/OpenBIC/commit/2a34c5b8edb70315fe2c7ef63faefcb9359d2c63,335709078,facebook/OpenBIC,False,False
cc325bac6738435b253f646344df404247fc09a6,"thrift struct node template//Summary:/simplifying the migration and establishing a pattern to follow in switch state nodes//- define USE_THRIFT_COW(NODE)/- define base as ThriftStructNode<NODE, THRIFT_TYPE>/- provide explicit template instantiation in corresponding cpp file.//for maps similar pattern exist//- define Traits/- define base as ThriftMapNode<MAP, Traits>/- provide explicit template instantiation in corresponding cpp file.//Following this address all compiler errors and avoid copy.//Reviewed By: peygar//Differential Revision:/D40918338//LaMa Project: L1125642//fbshipit-source-id: 6a3236a25ddbfc9d830db48650baad632832e210",https://github.com/facebook/fboss/commit/cc325bac6738435b253f646344df404247fc09a6,31927407,facebook/fboss,False,False
e4c05c8fe17d83a85f1105bc8580533317c1f7d6,"[clang] New preanalysis to substitute away mock pointers//Summary:/This aims to substitute away mock pointers from the code. This consists of a programming pattern where developers use global variables that contain a function pointer, where the function pointer points to the real function that we want to call in the production code, and gets swapped by a dummy function for testing.//Before, we had some support for this pattern in Pulse, but now we add support in the frontend: we identify such global function pointers, substitute their use with the actual function and remove the initializer code for such global variables.//The result is simpler code where Pulse analysis is easier to debug, and the analysis is also more performant, since fewer global variables are convoluting the state, and the method calls don't involve an extra step of calling the global initializer.//I left the Pulse support around because that's not specific to mock pointers, but works for any global function pointers.//Reviewed By: ezgicicek//Differential Revision:/D43838894//Privacy Context Container: L1122176//fbshipit-source-id: 3d3cbe9e2295b183b8ceeb26b5537dfbdeb4f979",https://github.com/facebook/infer/commit/e4c05c8fe17d83a85f1105bc8580533317c1f7d6,29857799,facebook/infer,False,False
07ea96ffe140089ed19b54cef31d4d144d4f437c,"Add multiline_parser support//Summary://FluentBit added support for multiline parsers on v1.8 (https://docs.fluentbit.io/manual/v/1.9-pre/administration/configuring-fluent-bit/multiline-parsing). On this commit we are adding support to the coobook to be able to configure them based on configurations.//While the `tail` input had multiline support in older version (via the `multiline` boolean property), the new one allows for more complex rules. (https://docs.fluentbit.io/manual/v/1.9-pre/pipeline/inputs/tail#multiline-support)//The parsers.conf will be appended according to the following:/```/node.default['fb_fluentbit']['multiline_parser']['my_multi_parse'] = {/  'type' => 'regex',/  'flush_timeout' => '1000',/  'rules' => [/    {/      'state_name' => 'start_state',/      'pattern' => '/^\d{4}\-\d{2}\-\d{2} \d{2}\:\d{2}\:\d{2},\d+ .*$/',/      'next_state' => 'cont',/    },/    {/      'state_name' => 'cont',/      'pattern' => '/^ - .*/',/      'next_state' => 'cont',/    },/  ],/}/```//Please read the FluentBit documentation for proper rules definitions: (https://docs.fluentbit.io/manual/v/1.9-pre/administration/configuring-fluent-bit/multiline-parsing#rules-definition)//Reviewed By: joshuamiller01, leoswaldo//Differential Revision: D41417395//fbshipit-source-id: 5380865d63ea07ce8da012fb6fcf16d4b45c465c",https://github.com/facebook/chef-cookbooks/commit/07ea96ffe140089ed19b54cef31d4d144d4f437c,48260686,facebook/chef-cookbooks,False,False
c826dc50de288758a0b783b2fd37b40a3b512fc4,"Add (Client) Functions as Form Actions (#26674)//This lets you pass a function to `<form action={...}>` or `<button//formAction={...}>` or `<input type=""submit formAction={...}>`. This will//behave basically like a `javascript:` URL except not quite implemented//that way. This is a convenience for the `onSubmit={e => {//e.preventDefault(); const fromData = new FormData(e.target); ... }`//pattern.////You can still implement a custom `onSubmit` handler and if it calls//`preventDefault`, it won't invoke the action, just like it would if you//used a full page form navigation or javascript urls. It behaves just//like a navigation and we might implement it with the Navigation API in//the future.////Currently this is just a synchronous function but in a follow up this//will accept async functions, handle pending states and handle errors.////This is implemented by setting `javascript:` URLs, but these only exist//to trigger an error message if something goes wrong instead of//navigating away. Like if you called `stopPropagation` to prevent React//from handling it or if you called `form.submit()` instead of//`form.requestSubmit()` which by-passes the `submit` event. If CSP is//used to ban `javascript:` urls, those will trigger errors when these//URLs are invoked which would be a different error message but it's still//there to notify the user that something went wrong in the plumbing.////Next up is improving the SSR state with action replaying and progressive//enhancement.",https://github.com/facebook/react/commit/c826dc50de288758a0b783b2fd37b40a3b512fc4,10270250,facebook/react,False,False
12a1d140e366aa8d95338e4412117f16da79a078,"Don't prerender siblings of suspended component  (#26380)//Today if something suspends, React will continue rendering the siblings//of that component.////Our original rationale for prerendering the siblings of a suspended//component was to initiate any lazy fetches that they might contain. This//was when we were more bullish about lazy fetching being a good idea some//of the time (when combined with prefetching), as opposed to our latest//thinking, which is that it's almost always a bad idea.////Another rationale for the original behavior was that the render was I/O//bound, anyway, so we might as do some extra work in the meantime. But//this was before we had the concept of instant loading states: when//navigating to a new screen, it's better to show a loading state as soon//as you can (often a skeleton UI), rather than delay the transition.//(There are still cases where we block the render, when a suitable//loading state is not available; it's just not _all_ cases where//something suspends.) So the biggest issue with our existing//implementation is that the prerendering of the siblings happens within//the same render pass as the one that suspended — _before_ the loading//state appears.////What we should do instead is immediately unwind the stack as soon as//something suspends, to unblock the loading state.////If we want to preserve the ability to prerender the siblings, what we//could do is schedule special render pass immediately after the fallback//is displayed. This is likely what we'll do in the future. However, in//the new implementation of `use`, there's another reason we don't//prerender siblings: so we can preserve the state of the stack when//something suspends, and resume where we left of when the promise//resolves without replaying the parents. The only way to do this//currently is to suspend the entire work loop. Fiber does not currently//support rendering multiple siblings in ""parallel"". Once you move onto//the next sibling, the stack of the previous sibling is discarded and//cannot be restored. We do plan to implement this feature, but it will//require a not-insignificant refactor.////Given that lazy data fetching is already bad for performance, the best//trade off for now seems to be to disable prerendering of siblings. This//gives us the best performance characteristics when you're following best//practices (i.e. hoist data fetches to Server Components or route//loaders), at the expense of making an already bad pattern a bit worse.////Later, when we implement resumable context stacks, we can reenable//sibling prerendering. Though even then the use case will mostly be to//prerender the CPU-bound work, not lazy fetches.",https://github.com/facebook/react/commit/12a1d140e366aa8d95338e4412117f16da79a078,10270250,facebook/react,False,False
034d76860cead1fa640edf49fdc0ee3f06c65be8,remove wildcard pattern matches of FlowLsp.server_state//Summary:/i am considering adding another constructor to this variant and so want it to be safe//Changelog: [internal]//Reviewed By: samwgoldman//Differential Revision: D38141733//fbshipit-source-id: 8af7435eb9ead47fb1122413b9affc5931a67045,https://github.com/facebook/flow/commit/034d76860cead1fa640edf49fdc0ee3f06c65be8,25880891,facebook/flow,False,False
0ffb15ecad9193d7f96036219f7eb2bab5b47332,refactor restoring packages from saved state//Summary:/moves restoring packages into the RestoreHeaps timer and makes it follow the same pattern as parsed and unparsed.//I didn't make it use the workers since there aren't that many packages and the overhead of workers on Windows is so high. perhaps we could have one set of workers do all 3 kinds of jobs though.//Changelog: [internal]//Reviewed By: samwgoldman//Differential Revision: D41061833//fbshipit-source-id: 541d39415f49fe46666c3e3c3e1af4d33cda6d0a,https://github.com/facebook/flow/commit/0ffb15ecad9193d7f96036219f7eb2bab5b47332,25880891,facebook/flow,False,False
6bab7e0924fb0a3e727db654b37554dfd6cf95f9,"GT/GTI: FW-util: Change GPU SXM from 0-based to 1-based (#3627)//Summary:/According to NV online#1069815 ""NVIDIA HGX Baseboard Redfish Design Collaterals"".//• Id pattern for GPUs are 1-based. Example: ""GPU_SXM_<1N>""//X-link: https://github.com/facebookexternal/openbmc.quanta/pull/3627//Test Plan:/1. Get version (Pass)/root@bmc-oob:~# fw-util hgx  --version/erot-gpu1 Version: 00.02.0083.0000_n00/erot-gpu2 Version: 00.02.0083.0000_n00/erot-gpu3 Version: 00.02.0083.0000_n00/erot-gpu4 Version: 00.02.0083.0000_n00//2. Update FW (Pass)/root@bmc-oob:~# fw-util hgx --update gpu3-fw /tmp/nvfw_HGX-H100x8_0003_230122.3.0_prod-signed.fwpkg target: {""HttpPushUriTargets"":[""/redfish/v1/UpdateService/FirmwareInventory/HGX_FW_GPU_SXM_3""]} Started update task: 0/The task with id 0 has started./Image '96.00.51.00.03' is being transferred to 'HGX_FW_GPU_SXM_3'. Awaiting for an action to proceed with activating image '96.00.51.00.03' on 'HGX_FW_GPU_SXM_3'. The task with id 0 has Completed./Update completed with state: Completed status: OK/Upgrade of hgx : gpu3-fw succeeded//Reviewed By: zhdaniel12//Differential Revision: D43504108//fbshipit-source-id: 0fbbcf9a14b73aacbfeffdc9d96c591db059611f",https://github.com/facebook/openbmc/commit/6bab7e0924fb0a3e727db654b37554dfd6cf95f9,31917712,facebook/openbmc,False,False
9686fab9332fee4fe724ce029cde36fca59e3cf7,"Refactor OptionsModal into UseModal//Summary:/We had a `useOptionsModal` utility, which creates a modal, adds it to a global state, then adds proper listeners for closing the modal on escape key, or if you click the 'x' in the top right, and sets up the right width for it, etc.//In this diff, I expand this to a more general `useModal` hook. This allows you to either use the more direct `{type: 'confirm', message: ..., buttons: ...}` API, or a more customizable `{type: 'custom', component: ...}` API. For file-a-bug, we'll use the more complicated API.//Without such a useModal util, right now you'd have to add a new <Modal> render on <App>, which needs its own global state management, then your own dismissing logic. This is sometimes needed, for example the Comparison View which does a lot of custom stuff.//But many smaller modals will fit a `useModal` pattern. For example, we may add a modal flow for Landing code, which would need custom rendering.//This API extension works like this://```tsx/function SomeComponent() {/  const showModal = useModal();/  return <div>/    <button onClick={async () => {/       const result = await showModal({/         type: 'custom',/         component: MyModalRendererComponent,/         title: 'hello'/       });/       // now result is what the modal returned to us, which we can use for further processing/    }/  </div>/}//type MyData = {foo: string};//function MyModalRendererComponent({returnResultAndDismiss}: {returnResultAndDismiss: (data: MyData) => void}) {/  return <div>/    Custom modal content!/    <button onClick={() => {/      returnResultAndDismiss({foo: 'bar'});/    }}>Return some data</button>/  </div>;/}/```//We'll use this API later in the stack for file-a-bug, where the modal contains all the file-a-bug fields (title, description, ...),/and it returns that data to the code path where we open the modal.//Reviewed By: bolinfest//Differential Revision: D42818652//fbshipit-source-id: 4616690363f744762f6a46abf677123008127813",https://github.com/facebook/sapling/commit/9686fab9332fee4fe724ce029cde36fca59e3cf7,58146669,facebook/sapling,False,False
30adbcc06404e8bd034b2d6909c3886a86456954,"service: remove race between mount shutdown and Thrift calls//Summary:/The isSafeForInodeAccess is used to know when the root inode is initialized and/valid, but this is used in racy context. For instance, the getMountPoints/collects all the mounts whose root inode is initialized, but then releases the/lock on the mountPoints_ list, subsequently, the EdenMount's root Inode is/accessed without checking. If the EdenMount is shutdown prior to the root Inode/being copied, the root Inode might be a nullptr, causing a NULL-dereference.//This pattern can be found in all of the Thrift entry points that play with/mounts and thus are all potentially sources of EdenFS crashes. To solve this,/we need to guarantee 2 things:/ - isSafeForInodeAccess must only change state while the mountPoints_ lock is/   held, specifically at shutdown time,/ - The root inode must be copied while the mountPoints_ lock is held.//This diff does both. For the second one in particular EdenServer::getMount is/modified to also return the root Inode. This is done instead of introducing a new/function to prevent future bugs from seeping in that may be missed at review time.//Reviewed By: chadaustin//Differential Revision: D42563083//fbshipit-source-id: c0267277a54c425f330bbd58d1dc86ec3746502d",https://github.com/facebook/sapling/commit/30adbcc06404e8bd034b2d6909c3886a86456954,58146669,facebook/sapling,False,False
c650da95c4afe57eef72e4d224144d08d3454ae1,"1/3 add ServerProgress.Errors library//Summary:/This diff adds an API, `ServerProgress.Errors`, for the streaming error file. This is its design:/```/OVERVIEW OF STREAMING ERRORS FILE//Errors is a file in /tmp/hh_server/<repo>/errors.bin which is written/by server during a typecheck. The file is first created when the server/starts its first typecheck, gets errors appended to it as the typecheck/discovers them, is unlinked and then another one with the same name/created each time the server starts another typecheck, and the file is finally/unlinked upon server exit. A ""typecheck"" can be thought of as a typecheck of the/entire program, and hence the errors file will contain every error reported in WWW./But in reality the server does tricks to typecheck a smaller number of files just/so long as it still manages to report every error into the file.//Therefore: a client can at any time open an file descriptor to this file,/and ""tail -f -n +1"" (i.e. read from the start and then follow) to follow/the typecheck that is currently underway or most recently completed, from its/start to its end. It will still be able to read the file descriptor through/to its end even if, in the meantime, a new typecheck has started and the old/file has been unlinked. Note that a given file-descriptor will only ever point/to a file which monitonically grows.//The server can have its typecheck interrupted. Some interruptions like watchman/will cause the current typecheck to be cancelled, then a new typecheck started./In this case the existing errors file will be unlinked, a new errors file created/for the new typecheck, and a sentinel will be written into the old file descriptor/to show that it ended before completing. Other interruptions like from/""hh --type-at-pos"" will have no effect: the current typecheck file can continue/being read just fine. If a client reads a file descriptor on its sentinel, that is/a guarantee that a new errors file is already in place and can be opened (or,/if no errors file exists, that can only be because the server has terminated).//If file does not exist, the client knows that either there is no server, or there/is one but it has not yet started typechecking (it might still be loading saved state)./In either case it is appropriate for the client to clientConnect {autostart_server=true}/in the normal way, until it establishes a connection to the server, and then it can/wait for the errors file.//SEMANTICS OF ERRORS-FILE CONTENTS//* An errors-file is tied to a particular watchman clock value. It reflects/  all file-changes that happened prior to the clock. (As to whether it reflects/  any file-changes that happened after the clock, that is impossible to tell.)/* As mentioned above, when the errors-file is complete, it contains the full/  set of errors that hh_server knows about for the project./* Each error report is an Errors.error list Relative_path.map, i.e. it encompasses/  several files, and for each file it has a list of errors. Currently we make/  one report for all ""duplicate name"" errors across the project if any, followed by/  one report per batch that had errors. This means that a file might be mentioned/  twice, once in a ""duplicate name"" report, once later. This will change in future/  so that each file is reported only once./* It currently does not write empty reports, though that might change in future/  (e.g. we might decide to write ""no errors in file a.php"" for a file which/  previously did have errors)./* Within a single report, the error list has been sorted and de-duped./```//There are a few design decisions not mentioned in the doc-comments which I'll note here.../1. I decided to stick this into the existing `ServerProgress.ml` rather than making a new file or new buck target. That's because it feels like progress.json and errors.bin are so very similar./   1. However, ServerProgressLwt.ml has to be a separate module, because hh_server isn't allowed to link to Lwt/   2. We have an existing convention that ""server/monitorConnection"" is a low-level module that combines RPC types, writing and reading functions. Similarly, ""server/serverProgress"" is a module that combines RPC types, writing and reading functions./2. I decided to make all the functions global. That reflects the fact that `root` is already global in both the server and client binaries (e.g. through Relative_path.set_prefix). It also reflects the fact that only one instance of hh_server can even exist for a given repository. That's as global as you can get!/3. We have to deal with what happens when a client connects to an errors.bin that was written by a later or earlier version of hh_server. I copied our existing pattern from monitorConnection, of having a loosely typed field `extra : Hh_json.json`, to allow for forward and backward compatibility without breaking the serialization format./4. `ignore_hh_version` is currently controlled by the server, and I preserved that behavior. Thus for instance `hh start --ignore-hh-version` will allow all versions of the client to connect to it. (But using the flag in the client doesn't allow it to connect to arbitrary versions of the server).//## How to review this diff/1. Although it says ""1300 lines changed in this diff"", 650 of them are tests and 100 of them are docblocks, so it's really only 550 lines.../2. Read the big block of text in the summary/3. Read the `test_completed` and `test_async_read_completed ` unit tests. They show straightforward success cases that illustrate the API for consuming errors./4. Focus on the producing side now. Read the ServerProgress.mli docblock on `write_state`, and docblocks for the other producing APIs in this module `new_empty_file`, `report`, `complete`, `unlink`. Now read the unit test case `test_produce_disordered`. This shows the ""state-machine model"" for producing errors./5. Read ServerProgress.ml for the implementation. From a concurrency correctness perspective, focus on `with_lock`, `write_message`, `read_message`, `unlink_sentinel_close`. The rest of the methods are straightforward./6. Read SeverProgressLwt.{mli,ml}//Reviewed By: CatherineGasnier//Differential Revision: D44159582//fbshipit-source-id: d469c91de267947fa490d3d47e152843439c97c3",https://github.com/facebook/hhvm/commit/c650da95c4afe57eef72e4d224144d08d3454ae1,455600,facebook/hhvm,False,False
d8aee3da2aa57ec373a0aa01c396b47d7f59e9f2,"Implement nested operations whereby RSC is set during render (and nested render) phase, and LSC is set during layout (and nested layout) phase//Summary:/In this diff, an RSC is set on the CC during the render phase, and a LSC is set during layout phase. In between these phases, the respective context is cleared.//This diff also introduces this pattern for ""nested"" operations, such as during component.measure & layout.measureNestedTree - which both save the ""current"" state-context, then set their own sequence of RSC & LSC, and finish by restoring the previous state-context.//For tests, the major difference here is that we no longer simply need to set a LSC-for-tests. Instead, an RSC is usually expected. To that end, a new set-RSC-for-tests method has been added to CC.//All litho tests and test helpers have been adapted to this new paradigm//Reviewed By: astreet//Differential Revision: D39502953//fbshipit-source-id: 7630fb996ef09d46096dcdb317834296073f4d94",https://github.com/facebook/litho/commit/d8aee3da2aa57ec373a0aa01c396b47d7f59e9f2,80179724,facebook/litho,False,False
075de45076be8634339d20ecd0f8a92bb7b4ae3a,"Bump react-refresh from 0.11.0 to 0.14.0 in /desktop (#4540)//Summary:/Bumps [react-refresh](https://github.com/facebook/react/tree/HEAD/packages/react) from 0.11.0 to 0.14.0./<details>/<summary>Release notes</summary>/<p><em>Sourced from <a href=""https://github.com/facebook/react/releases"">react-refresh's releases</a>.</em></p>/<blockquote>/<h2>v0.14.0</h2>/<p>See <a href=""http://facebook.github.io/react/blog/2015/10/07/react-v0.14.html"">http://facebook.github.io/react/blog/2015/10/07/react-v0.14.html</a>.</p>/<h2>v0.13.3</h2>/<h3>React Core</h3>/<h4>New Features</h4>/<ul>/<li>Added <code>clipPath</code> element and attribute for SVG</li>/<li>Improved warnings for deprecated methods in plain JS classes</li>/</ul>/<h4>Bug Fixes</h4>/<ul>/<li>Loosened <code>dangerouslySetInnerHTML</code> restrictions so <code>{__html: undefined}</code> will no longer throw</li>/<li>Fixed extraneous context warning with non-pure <code>getChildContext</code></li>/<li>Ensure <code>replaceState(obj)</code> retains prototype of <code>obj</code></li>/</ul>/<h3>React with Add-ons</h3>/<h3>Bug Fixes</h3>/<ul>/<li>Test Utils: Ensure that shallow rendering works when components define <code>contextTypes</code></li>/</ul>/<h2>v0.13.2</h2>/<h3>React Core</h3>/<h4>New Features</h4>/<ul>/<li>Added <code>strokeDashoffset</code>, <code>flexPositive</code>, <code>flexNegative</code> to the list of unitless CSS properties</li>/<li>Added support for more DOM properties:/<ul>/<li><code>scoped</code> - for <code>&lt;style&gt;</code> elements</li>/<li><code>high</code>, <code>low</code>, <code>optimum</code> - for <code>&lt;meter&gt;</code> elements</li>/<li><code>unselectable</code> - IE-specific property to prevent user selection</li>/</ul>/</li>/</ul>/<h4>Bug Fixes</h4>/<ul>/<li>Fixed a case where re-rendering after rendering null didn't properly pass context</li>/<li>Fixed a case where re-rendering after rendering with <code>style={null}</code> didn't properly update <code>style</code></li>/<li>Update <code>uglify</code> dependency to prevent a bug in IE8</li>/<li>Improved warnings</li>/</ul>/<h3>React with Add-Ons</h3>/<h4>Bug Fixes</h4>/<ul>/<li>Immutabilty Helpers: Ensure it supports <code>hasOwnProperty</code> as an object key</li>/</ul>/<h3>React Tools</h3>/<ul>/<li>Improve documentation for new options</li>/</ul>/<h2>v0.13.1</h2>/<h3>React Core</h3>/<h4>Bug Fixes</h4>/<ul>/<li>Don't throw when rendering empty <code>&lt;select&gt;</code> elements</li>/<li>Ensure updating <code>style</code> works when transitioning from <code>null</code></li>/</ul>//</blockquote>/<p>... (truncated)</p>/</details>/<details>/<summary>Changelog</summary>/<p><em>Sourced from <a href=""https://github.com/facebook/react/blob/main/CHANGELOG.md"">react-refresh's changelog</a>.</em></p>/<blockquote>/<h2>0.14.0 (October 7, 2015)</h2>/<h3>Major changes</h3>/<ul>/<li>Split the main <code>react</code> package into two: <code>react</code> and <code>react-dom</code>.  This paves the way to writing components that can be shared between the web version of React and React Native.  This means you will need to include both files and some functions have been moved from <code>React</code> to <code>ReactDOM</code>.</li>/<li>Addons have been moved to separate packages (<code>react-addons-clone-with-props</code>, <code>react-addons-create-fragment</code>, <code>react-addons-css-transition-group</code>, <code>react-addons-linked-state-mixin</code>, <code>react-addons-perf</code>, <code>react-addons-pure-render-mixin</code>, <code>react-addons-shallow-compare</code>, <code>react-addons-test-utils</code>, <code>react-addons-transition-group</code>, <code>react-addons-update</code>, <code>ReactDOM.unstable_batchedUpdates</code>).</li>/<li>Stateless functional components - React components were previously created using React.createClass or using ES6 classes.  This release adds a <a href=""https://reactjs.org/docs/reusable-components.html#stateless-functions"">new syntax</a> where a user defines a single <a href=""https://reactjs.org/docs/reusable-components.html#stateless-functions"">stateless render function</a> (with one parameter: <code>props</code>) which returns a JSX element, and this function may be used as a component.</li>/<li>Refs to DOM components as the DOM node itself. Previously the only useful thing you can do with a DOM component is call <code>getDOMNode()</code> to get the underlying DOM node. Starting with this release, a ref to a DOM component <em>is</em> the actual DOM node. <strong>Note that refs to custom (user-defined) components work exactly as before; only the built-in DOM components are affected by this change.</strong></li>/</ul>/<h3>Breaking changes</h3>/<ul>/<li><code>React.initializeTouchEvents</code> is no longer necessary and has been removed completely. Touch events now work automatically.</li>/<li>Add-Ons: Due to the DOM node refs change mentioned above, <code>TestUtils.findAllInRenderedTree</code> and related helpers are no longer able to take a DOM component, only a custom component.</li>/<li>The <code>props</code> object is now frozen, so mutating props after creating a component element is no longer supported. In most cases, <a href=""https://reactjs.org/docs/react-api.html#cloneelement""><code>React.cloneElement</code></a> should be used instead. This change makes your components easier to reason about and enables the compiler optimizations mentioned above.</li>/<li>Plain objects are no longer supported as React children; arrays should be used instead. You can use the <a href=""https://reactjs.org/docs/create-fragment.html""><code>createFragment</code></a> helper to migrate, which now returns an array.</li>/<li>Add-Ons: <code>classSet</code> has been removed. Use <a href=""https://github.com/JedWatson/classnames"">classnames</a> instead.</li>/<li>Web components (custom elements) now use native property names.  Eg: <code>class</code> instead of <code>className</code>.</li>/</ul>/<h3>Deprecations</h3>/<ul>/<li><code>this.getDOMNode()</code> is now deprecated and <code>ReactDOM.findDOMNode(this)</code> can be used instead. Note that in the common case, <code>findDOMNode</code> is now unnecessary since a ref to the DOM component is now the actual DOM node.</li>/<li><code>setProps</code> and <code>replaceProps</code> are now deprecated. Instead, call ReactDOM.render again at the top level with the new props.</li>/<li>ES6 component classes must now extend <code>React.Component</code> in order to enable stateless function components. The <a href=""https://reactjs.org/blog/2015/01/27/react-v0.13.0-beta-1.html#other-languages"">ES3 module pattern</a> will continue to work.</li>/<li>Reusing and mutating a <code>style</code> object between renders has been deprecated. This mirrors our change to freeze the <code>props</code> object.</li>/<li>Add-Ons: <code>cloneWithProps</code> is now deprecated. Use <a href=""https://reactjs.org/docs/react-api.html#cloneelement""><code>React.cloneElement</code></a> instead (unlike <code>cloneWithProps</code>, <code>cloneElement</code> does not merge <code>className</code> or <code>style</code> automatically; you can merge them manually if needed).</li>/<li>Add-Ons: To improve reliability, <code>CSSTransitionGroup</code> will no longer listen to transition events. Instead, you should specify transition durations manually using props such as <code>transitionEnterTimeout={500}</code>.</li>/</ul>/<h3>Notable enhancements</h3>/<ul>/<li>Added <code>React.Children.toArray</code> which takes a nested children object and returns a flat array with keys assigned to each child. This helper makes it easier to manipulate collections of children in your <code>render</code> methods, especially if you want to reorder or slice <code>this.props.children</code> before passing it down. In addition, <code>React.Children.map</code> now returns plain arrays too.</li>/<li>React uses <code>console.error</code> instead of <code>console.warn</code> for warnings so that browsers show a full stack trace in the console. (Our warnings appear when you use patterns that will break in future releases and for code that is likely to behave unexpectedly, so we do consider our warnings to be “must-fix” errors.)</li>/<li>Previously, including untrusted objects as React children <a href=""http://danlec.com/blog/xss-via-a-spoofed-react-element"">could result in an XSS security vulnerability</a>. This problem should be avoided by properly validating input at the application layer and by never passing untrusted objects around your application code. As an additional layer of protection, <a href=""https://github-redirect.dependabot.com/facebook/react/pull/4832"">React now tags elements</a> with a specific <a href=""http://www.2ality.com/2014/12/es6-symbols.html"">ES2015 (ES6) <code>Symbol</code></a> in browsers that support it, in order to ensure that React never considers untrusted JSON to be a valid element. If this extra security protection is important to you, you should add a <code>Symbol</code> polyfill for older browsers, such as the one included by <a href=""https://babeljs.io/docs/usage/polyfill/"">Babel’s polyfill</a>.</li>/<li>When possible, React DOM now generates XHTML-compatible markup.</li>/<li>React DOM now supports these standard HTML attributes: <code>capture</code>, <code>challenge</code>, <code>inputMode</code>, <code>is</code>, <code>keyParams</code>, <code>keyType</code>, <code>minLength</code>, <code>summary</code>, <code>wrap</code>. It also now supports these non-standard attributes: <code>autoSave</code>, <code>results</code>, <code>security</code>.</li>/<li>React DOM now supports these SVG attributes, which render into namespaced attributes: <code>xlinkActuate</code>, <code>xlinkArcrole</code>, <code>xlinkHref</code>, <code>xlinkRole</code>, <code>xlinkShow</code>, <code>xlinkTitle</code>, <code>xlinkType</code>, <code>xmlBase</code>, <code>xmlLang</code>, <code>xmlSpace</code>.</li>/<li>The <code>image</code> SVG tag is now supported by React DOM.</li>/<li>In React DOM, arbitrary attributes are supported on custom elements (those with a hyphen in the tag name or an <code>is=&quot;...&quot;</code> attribute).</li>/<li>React DOM now supports these media events on <code>audio</code> and <code>video</code> tags: <code>onAbort</code>, <code>onCanPlay</code>, <code>onCanPlayThrough</code>, <code>onDurationChange</code>, <code>onEmptied</code>, <code>onEncrypted</code>, <code>onEnded</code>, <code>onError</code>, <code>onLoadedData</code>, <code>onLoadedMetadata</code>, <code>onLoadStart</code>, <code>onPause</code>, <code>onPlay</code>, <code>onPlaying</code>, <code>onProgress</code>, <code>onRateChange</code>, <code>onSeeked</code>, <code>onSeeking</code>, <code>onStalled</code>, <code>onSuspend</code>, <code>onTimeUpdate</code>, <code>onVolumeChange</code>, <code>onWaiting</code>.</li>/<li>Many small performance improvements have been made.</li>/<li>Many warnings show more context than before.</li>/<li>Add-Ons: A <a href=""https://github-redirect.dependabot.com/facebook/react/pull/3355""><code>shallowCompare</code></a> add-on has been added as a migration path for <code>PureRenderMixin</code> in ES6 classes.</li>/<li>Add-Ons: <code>CSSTransitionGroup</code> can now use <a href=""https://github.com/facebook/react/blob/48942b85/docs/docs/10.1-animation.md#custom-classes"">custom class names</a> instead of appending <code>-enter-active</code> or similar to the transition name.</li>/</ul>/<h3>New helpful warnings</h3>/<ul>/<li>React DOM now warns you when nesting HTML elements invalidly, which helps you avoid surprising errors during updates.</li>/<li>Passing <code>document.body</code> directly as the container to <code>ReactDOM.render</code> now gives a warning as doing so can cause problems with browser extensions that modify the DOM.</li>/<li>Using multiple instances of React together is not supported, so we now warn when we detect this case to help you avoid running into the resulting problems.</li>/</ul>//</blockquote>/<p>... (truncated)</p>/</details>/<details>/<summary>Commits</summary>/<ul>/<li><a href=""https://github.com/facebook/react/commit/3603d45157e6c1b21cda7ed96683408b319ae619""><code>3603d45</code></a> v0.14.0</li>/<li><a href=""https://github.com/facebook/react/commit/693dd3567b6648fdccfd602702192bb22f405e63""><code>693dd35</code></a> Update to fbjs@0.3</li>/<li><a href=""https://github.com/facebook/react/commit/4a4174b9e8d1f554a5368da5df274746a8e332d1""><code>4a4174b</code></a> 0.14.0-rc1</li>/<li><a href=""https://github.com/facebook/react/commit/c04d02e5e8de18436ac95037ab856ac5ba7d29b9""><code>c04d02e</code></a> Add warnings to React module</li>/<li><a href=""https://github.com/facebook/react/commit/52b4c9eabf6c5930a906df4584c8480db5ec6e9e""><code>52b4c9e</code></a> Upgrade to fbjs, fbjs-scripts @ 0.2</li>/<li><a href=""https://github.com/facebook/react/commit/b38509cade7e5e31bffd2da93fb0213ad58681bf""><code>b38509c</code></a> Merge pull request <a href=""https://github.com/facebook/react/tree/HEAD/packages/react/issues/4540"">https://github.com/facebook/flipper/issues/4540</a> from scottburch/ie8-fix</li>/<li><a href=""https://github.com/facebook/react/commit/ecb34de5747a6d4578dc4be920a033db9f81370f""><code>ecb34de</code></a> Upgrade ESLint, fix code</li>/<li><a href=""https://github.com/facebook/react/commit/3f6bca7b1638ee940bb01989377abc9864edb6fe""><code>3f6bca7</code></a> 0.14.0-beta3</li>/<li><a href=""https://github.com/facebook/react/commit/5f01a90954405d26439d00af2b6f5dbfa535ef9d""><code>5f01a90</code></a> Update addons.js</li>/<li><a href=""https://github.com/facebook/react/commit/1da2b29897781d3faa7b555e4962d7eb5b6a2707""><code>1da2b29</code></a> added suggested comment to get file to pass es-lint</li>/<li>Additional commits viewable in <a href=""https://github.com/facebook/react/commits/v0.14.0/packages/react"">compare view</a></li>/</ul>/</details>/<details>/<summary>Maintainer changes</summary>/<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~gnoff"">gnoff</a>, a new releaser for react-refresh since your current version.</p>/</details>/<br />//[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=react-refresh&package-manager=npm_and_yarn&previous-version=0.11.0&new-version=0.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)//Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `dependabot rebase`.//[//]: # (dependabot-automerge-start)/[//]: # (dependabot-automerge-end)// ---//<details>/<summary>Dependabot commands and options</summary>/<br />//You can trigger Dependabot actions by commenting on this PR:/- `dependabot rebase` will rebase this PR/- `dependabot recreate` will recreate this PR, overwriting any edits that have been made to it/- `dependabot merge` will merge this PR after your CI passes on it/- `dependabot squash and merge` will squash and merge this PR after your CI passes on it/- `dependabot cancel merge` will cancel a previously requested merge and block automerging/- `dependabot reopen` will reopen this PR if it is closed/- `dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually/- `dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)/- `dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)/- `dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)//</details>//Pull Request resolved: https://github.com/facebook/flipper/pull/4540//Reviewed By: ivanmisuno//Differential Revision: D44215184//Pulled By: mweststrate//fbshipit-source-id: e8f33dfbfbe887d49c27f2dabbbc1548de3d10e9",https://github.com/facebook/flipper/commit/075de45076be8634339d20ecd0f8a92bb7b4ae3a,129283183,facebook/flipper,False,False
23a11539ba3f5ca0d374afdb1f1049eeac789eb3,"Return Result types for Failed Queries rather than throwing exceptions//Summary:/**TLDR**: Instead of propagating exceptions due to failed queries all the way up the call stack to be caught, instead return Result types to be processed by the caller.//The reason we want to return result types is that we already know in advance that it's a very possible circumstance that we will encounter a query error. Borrowing from a principle in functional programming, we are adapting an either type pattern where we will return either a valid response, or a Failure. In case you have no context on this topic, here's a helpful article (https://dev.to/anthonyjoeseph/either-vs-exception-handling-3jmg)//The purpose of this diff stack is to log exceptions for LSP events to scuba. Before that can be done, there are issues in which I cannot log exceptions to scuba because they are being caught at too low a level to be written to telemetry. This diff focuses on getting us to a state where we can log those exceptions, and in a future diff, we will actually perform that logging.//I changed the unit tests to reflect that most of the operations throw exceptions now rather than returning empty responses.//Reviewed By: stroxler//Differential Revision: D40239217//fbshipit-source-id: 8bb70c4d08c7e7cf520810d681ad564bbd517da6",https://github.com/facebook/pyre-check/commit/23a11539ba3f5ca0d374afdb1f1049eeac789eb3,110274488,facebook/pyre-check,False,False
2ed12e1a1486afa418244f68dac4ac4979a3492f,Exception handling in absint//Summary:/The current absint framework provides a Exception CFG but it/handles exception edges as normal edges. We separate the two notions/when computing the predecessor abstraction of a node and we carefully/turn an exception state into a normal state when reaching a handler./We activate this framework on Pulse and test it on simple Java resource/open/close patterns relying on try..finally./We don't handle `catch` very precisely for the moment since we do not record/the thrown exception object.//Reviewed By: skcho//Differential Revision: D33017691//fbshipit-source-id: 1c4759e6d8,https://github.com/facebook/infer/commit/2ed12e1a1486afa418244f68dac4ac4979a3492f,29857799,facebook/infer,False,False
4feee43eb38cb10bc62504b0965590dba7e9f73c,"invert the sense of happly_decl_has_no_reified_generics()//Summary:/This is the first place in hackc we call a DeclProvider to resolve external/classnames. I started to refine it's api to be a tri-state so we can distinguish/""I don't know"" cases from ""definitely yes"" and ""definitely no"", but managed/to hopelessly confuse myself with double negatives.//This diff flips the sense of the API to match the comment, and adds some/asserts and exhaustive pattern matches, but should result in no bytecode changes/(with or without DeclProviders).//Reviewed By: aorenste//Differential Revision: D34617436//fbshipit-source-id: a0f581a243edeb95b432f6c87f5291014e3ec421",https://github.com/facebook/hhvm/commit/4feee43eb38cb10bc62504b0965590dba7e9f73c,455600,facebook/hhvm,False,False
85d8b6f947d4d1b02c4831108754fe403e72f37a,Refactor naming_coroutine_check away from iter_with_state pattern//Summary: Refactor check away from using the `iter_with_state` pattern.//Reviewed By: kmeht//Differential Revision: D14296228//fbshipit-source-id: 81258033359628081fa3208311163449c1f00363,https://github.com/facebook/hhvm/commit/85d8b6f947d4d1b02c4831108754fe403e72f37a,455600,facebook/hhvm,False,False
6af568b764e9540771aaddf3e18fec5a37b477d2,"interprocedural analysis and allowing benign code patterns in clinit_may_have_side_effects//Summary:/Static initializers often contain actually benign code. Benign meaning here code that 1) doesn’t trigger other clinits with side-effects, and 2) doesn’t mutate any observable state. (Let’s ignore more obscure issues such as exceptions and non-termination for now. )//In this diff, we do a very simple interprocedural analysis to peek into a clinit's callees, and we white-list certain external framework references. Some framework references are ""clearly"" benign (pattern 1), some are ""probably"" benign (pattern 2), and some are ""clearly not, but in since we've been doing it in the past, probably"" benign (pattern 3).//Clearly, this analysis is not sound, as it doesn't do a precise data-flow analysis, and then just look at pattern 2 and 3... However, to me it still seems to strike a reasonable balance between clearly non-benign code while keeping the overhead of static initialization reasonable. We can keep improving on this later, while increasing the fidelity of static initialization semantics now.//PATTERN 1: CERTAINLY BENIGN EXTERNAL REFERENCES/Static initializers often creates instances of framework classes like an ArrayList, and maybe adding some elements to it.//PATTERN 2: PROBABLY BENIGN EXTERNAL REFERENCES/Static initializers also often create instances of classes like an HashSet, and add elements to it. That isn’t actually guaranteed to be benign, as it may execute potentially arbitrary code by invoking .hashCode and .equals methods. While we could do some sophisticated analysis to figure this out, it’s probably benign.//PATTERN 3: CLEARLY SIDE-EFFECTING EXTERNAL METHODS THAT STILL DON’T ACTUALLY MATTER/Calls to java.util.logging.Logger.log will clearly have an observable side-effect, and yet, it probably doesn’t matter for app functionality. Moving around the time java.lang.System.currentTimeMillis() is called clearly has some implications, but if we used to do that in the past, it’s probably not a functional issue...//Reviewed By: kathryngray//Differential Revision: D31257522//fbshipit-source-id: 7c5bde31ffc66f8c5c6c6d9207fe083638a50007",https://github.com/facebook/redex/commit/6af568b764e9540771aaddf3e18fec5a37b477d2,54664770,facebook/redex,False,False
e890c6d772816c9d9b90b6c8bf5da18994ee27c0,"Have AstEnvironment fully own the module tracker//Summary:/The root cause of a lot of our problems with testing APIs -/which also makes production codepaths harder to understand - is that/instead of creating the entire environment stack at once we create/some of the bottom layers first and then pass them into higher layers.//This dependency injection pattern might be good for its flexibility,/except that there's a catch: the control flow in push updates means/that we need a higher-level environment layer to *completely* own/lower levels, because it creates illegal states if the lower levels/are ever updated without updating the higher levels.//This is something we can fix by having appropriate creation apis/at all layers so that they can construct their own (hidden) inner/layers, which guarantees that the update rules are never violated.//To do this, we need to have three creation apis:/- create, used for all from-scratch environments in production/- load, used to load from a saved state/- create_for_testing, used to create an environment that is backed/  by in-memory sources (and cannot be updated).//This commit updates AstEnvironment to expose these three apis,/in the next commit I'll update the higher-level environments to/do the same.//Differential Revision: D36881932//fbshipit-source-id: dfb58aa4361157bfbb5bdce1e7a88972504485c2",https://github.com/facebook/pyre-check/commit/e890c6d772816c9d9b90b6c8bf5da18994ee27c0,110274488,facebook/pyre-check,False,False
68ab9bde9bc018dc1947f2b178b6abbe6ebbe8a6,"Refactor nast_reactivity_check away from iter_with_state_pattern//Summary: This check was added on 2/22/2019 (D14121615), and is likely responsible for some performance regressions. Moving away from this iter with state pattern should improve the issue.//Differential Revision: D14307779//fbshipit-source-id: a9078e7bade6971612ff4b2f7f79de3f70deb0b5",https://github.com/facebook/hhvm/commit/68ab9bde9bc018dc1947f2b178b6abbe6ebbe8a6,455600,facebook/hhvm,False,False
c6e9525d3bfa02d89a1ea651f11d4c54e278dbc9,"refactor context_control_check away from iter_with_state pattern//Summary:/I'm hoping to test the performance of the `iter_with_state` pattern with these diffs.//Also, moves some of the ctx fields to the environment fields on nast_check so other checks can take advantage of them.//Reviewed By: kmeht//Differential Revision: D14297741//fbshipit-source-id: f63fcb05a64b3c15d561b5b79a0d177db59d89e7",https://github.com/facebook/hhvm/commit/c6e9525d3bfa02d89a1ea651f11d4c54e278dbc9,455600,facebook/hhvm,False,False
c8b9f407afeffc258b1d1660463f30d49561f531,"Protect getProgrammedState with a mutex//Summary:/Acquire mutex to guard against picking up a stale programmed/state. A state update maybe in progress. A common pattern in/tests is to get the current programmedState, make changes to/it and then call applyNewState. If a state update is in/progress when you query programmedState_, you risk undoing/the changes of ongoing state update.//Reviewed By: shri-khare//Differential Revision: D23258181//fbshipit-source-id: d14312f168b3d29884a0c19e7fd22aaeda4a45e9",https://github.com/facebook/fboss/commit/c8b9f407afeffc258b1d1660463f30d49561f531,31927407,facebook/fboss,False,False
86ead2eb964e09b25fa38f35ed622a54acde87f8,"Tighten companion-by-udid invariants//Summary:/The intent here is to take domain logic out of the CompanionSet. This makes it even more of a dumb wrapper around state.//As a result of this change, we can tighten invariants within the ManagementClient://- Companion spawning will fail earlier if there's no matching target for a given udid./- Explicit fallback of ""no local targets"" when running in ""companionless"" environments./- No re-raising of exceptions/- Case analysis (closer to pattern matching) for all of the ""companion by udid"" cases.//Reviewed By: jbardini//Differential Revision: D31994843//fbshipit-source-id: be92077cef16f0f719f86c8daa9cd65256076d24",https://github.com/facebook/idb/commit/86ead2eb964e09b25fa38f35ed622a54acde87f8,41870517,facebook/idb,False,False
3a64804b41df9af1ebb1b7f97586f74278a89edb,"[erl-pulse] Bugfix in handling dynamic types//Summary:/Pulse models for built-in Erlang functions sometimes have the pattern/""if type of x is T, then access these fields of x"". The ""if"" part was/sometimes producing a subtly unsatisfiable state: attributes say that x/is an invalid reference, but path condition requires that x has type T./This led to a crash.//The fix here works by not producing ""subtly unsatisfiable"" states, but/by explicitly pruning the exploration of such execution paths.//Reviewed By: mmarescotti//Differential Revision: D31543370//fbshipit-source-id: 88cd4299e",https://github.com/facebook/infer/commit/3a64804b41df9af1ebb1b7f97586f74278a89edb,29857799,facebook/infer,False,False
875b48aba30cf7dcb03ecb3d5cb16f1ccfda6843,"[inline-requires] Make named imports work (#246)//Patterns like `import {name} from 'module'` were not working properly.//This adds support for that pattern.////In addition, state is local to the traversal, to avoid leaking paths after using the plugin.",https://github.com/facebook/fbjs/commit/875b48aba30cf7dcb03ecb3d5cb16f1ccfda6843,36469177,facebook/fbjs,False,False
25d8341f9750a8825dcdb7762d0bc9843814520f,Optimize ConcatStrStr pairs to ConcatStr3//Summary:/When we see a pattern where/```/t1 = ConcatStrStr a b/t2 = ConcatStrStr t1 c/```/we can convert this into/```/t2 = ConcatStr3 a b c/```/if all uses of `t1` are/* `t2 = ConcatStrStr t1 c`/* `Decref t1`/* `StStk` in catch traces//Note: `StStk` in catch traces comes from bringing the unwinder to a consistent state so that it properly unwind the stack.//Reviewed By: ottoni//Differential Revision: D28293952//fbshipit-source-id: 216c47d2400af57bb89fd8d9df1acdc357b00a90,https://github.com/facebook/hhvm/commit/25d8341f9750a8825dcdb7762d0bc9843814520f,455600,facebook/hhvm,False,False
5724348689c7b6f51a3bbca5723af2185b77653e,"Revamp, optimize new experimental clock cache (#10626)//Summary:/* Consolidates most metadata into a single word per slot so that more/can be accomplished with a single atomic update. In the common case,/Lookup was previously about 4 atomic updates, now just 1 atomic update./Common case Release was previously 1 atomic read + 1 atomic update,/now just 1 atomic update./* Eliminate spins / waits / yields, which likely threaten some ""lock free""/benefits. Compare-exchange loops are only used in explicit Erase, and/strict_capacity_limit=true Insert. Eviction uses opportunistic compare-/exchange./* Relaxes some aggressiveness and guarantees. For example,/  * Duplicate Inserts will sometimes go undetected and the shadow duplicate/    will age out with eviction./  * In many cases, the older Inserted value for a given cache key will be kept/  (i.e. Insert does not support overwrite)./  * Entries explicitly erased (rather than evicted) might not be freed/  immediately in some rare cases./  * With strict_capacity_limit=false, capacity limit is not tracked/enforced as/  precisely as LRUCache, but is self-correcting and should only deviate by a/  very small number of extra or fewer entries./* Use smaller ""computed default"" number of cache shards in many cases,/because benefits to larger usage tracking / eviction pools outweigh the small/cost of more lock-free atomic contention. The improvement in CPU and I/O/is dramatic in some limit-memory cases./* Even without the sharding change, the eviction algorithm is likely more/effective than LRU overall because it's more stateful, even though the/""hot path"" state tracking for it is essentially free with ref counting. It/is like a generalized CLOCK with aging (see code comments). I don't have/performance numbers showing a specific improvement, but in theory, for a/Poisson access pattern to each block, keeping some state allows better/estimation of time to next access (Poisson interval) than strict LRU. The/bounded randomness in CLOCK can also reduce ""cliff"" effect for repeated/range scans approaching and exceeding cache size.//## Hot path algorithm comparison/Rough descriptions, focusing on number and kind of atomic operations:/* Old `Lookup()` (2-5 atomic updates per probe):/```/Loop:/  Increment internal ref count at slot/  If possible hit:/    Check flags atomic (and non-atomic fields)/    If cache hit:/      Three distinct updates to 'flags' atomic/      Increment refs for internal-to-external/      Return/  Decrement internal ref count/while atomic read 'displacements' > 0/```/* New `Lookup()` (1-2 atomic updates per probe):/```/Loop:/  Increment acquire counter in meta word (optimistic)/  If visible entry (already read meta word):/    If match (read non-atomic fields):/      Return/    Else:/      Decrement acquire counter in meta word/  Else if invisible entry (rare, already read meta word):/    Decrement acquire counter in meta word/while atomic read 'displacements' > 0/```/* Old `Release()` (1 atomic update, conditional on atomic read, rarely more):/```/Read atomic ref count/If last reference and invisible (rare):/  Use CAS etc. to remove/  Return/Else:/  Decrement ref count/```/* New `Release()` (1 unconditional atomic update, rarely more):/```/Increment release counter in meta word/If last reference and invisible (rare):/  Use CAS etc. to remove/  Return/```//## Performance test setup/Build DB with/```/TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=fillrandom -num=30000000 -disable_wal=1 -bloom_bits=16/```/Test with/```/TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=readrandom -readonly -num=30000000 -bloom_bits=16 -cache_index_and_filter_blocks=1 -cache_size=${CACHE_MB}000000 -duration 60 -threads=$THREADS -statistics/```/Numbers on a single socket Skylake Xeon system with 48 hardware threads, DEBUG_LEVEL=0 PORTABLE=0. Very similar story on a dual socket system with 80 hardware threads. Using (every 2nd) Fibonacci MB cache sizes to sample the territory between powers of two. Configurations://base: LRUCache before this change, but with db_bench change to default cache_numshardbits=-1 (instead of fixed at 6)/folly: LRUCache before this change, with folly enabled (distributed mutex) but on an old compiler (sorry)/gt_clock: experimental ClockCache before this change/new_clock: experimental ClockCache with this change//## Performance test results/First test ""hot path"" read performance, with block cache large enough for whole DB:/4181MB 1thread base -> kops/s: 47.761/4181MB 1thread folly -> kops/s: 45.877/4181MB 1thread gt_clock -> kops/s: 51.092/4181MB 1thread new_clock -> kops/s: 53.944//4181MB 16thread base -> kops/s: 284.567/4181MB 16thread folly -> kops/s: 249.015/4181MB 16thread gt_clock -> kops/s: 743.762/4181MB 16thread new_clock -> kops/s: 861.821//4181MB 24thread base -> kops/s: 303.415/4181MB 24thread folly -> kops/s: 266.548/4181MB 24thread gt_clock -> kops/s: 975.706/4181MB 24thread new_clock -> kops/s: 1205.64 (~= 24 * 53.944)//4181MB 32thread base -> kops/s: 311.251/4181MB 32thread folly -> kops/s: 274.952/4181MB 32thread gt_clock -> kops/s: 1045.98/4181MB 32thread new_clock -> kops/s: 1370.38//4181MB 48thread base -> kops/s: 310.504/4181MB 48thread folly -> kops/s: 268.322/4181MB 48thread gt_clock -> kops/s: 1195.65/4181MB 48thread new_clock -> kops/s: 1604.85 (~= 24 * 1.25 * 53.944)//4181MB 64thread base -> kops/s: 307.839/4181MB 64thread folly -> kops/s: 272.172/4181MB 64thread gt_clock -> kops/s: 1204.47/4181MB 64thread new_clock -> kops/s: 1615.37//4181MB 128thread base -> kops/s: 310.934/4181MB 128thread folly -> kops/s: 267.468/4181MB 128thread gt_clock -> kops/s: 1188.75/4181MB 128thread new_clock -> kops/s: 1595.46//Whether we have just one thread on a quiet system or an overload of threads, the new version wins every time in thousand-ops per second, sometimes dramatically so. Mutex-based implementation quickly becomes contention-limited. New clock cache shows essentially perfect scaling up to number of physical cores (24), and then each hyperthreaded core adding about 1/4 the throughput of an additional physical core (see 48 thread case). Block cache miss rates (omitted above) are negligible across the board. With partitioned instead of full filters, the maximum speed-up vs. base is more like 2.5x rather than 5x.//Now test a large block cache with low miss ratio, but some eviction is required:/1597MB 1thread base -> kops/s: 46.603 io_bytes/op: 1584.63 miss_ratio: 0.0201066 max_rss_mb: 1589.23/1597MB 1thread folly -> kops/s: 45.079 io_bytes/op: 1530.03 miss_ratio: 0.019872 max_rss_mb: 1550.43/1597MB 1thread gt_clock -> kops/s: 48.711 io_bytes/op: 1566.63 miss_ratio: 0.0198923 max_rss_mb: 1691.4/1597MB 1thread new_clock -> kops/s: 51.531 io_bytes/op: 1589.07 miss_ratio: 0.0201969 max_rss_mb: 1583.56//1597MB 32thread base -> kops/s: 301.174 io_bytes/op: 1439.52 miss_ratio: 0.0184218 max_rss_mb: 1656.59/1597MB 32thread folly -> kops/s: 273.09 io_bytes/op: 1375.12 miss_ratio: 0.0180002 max_rss_mb: 1586.8/1597MB 32thread gt_clock -> kops/s: 904.497 io_bytes/op: 1411.29 miss_ratio: 0.0179934 max_rss_mb: 1775.89/1597MB 32thread new_clock -> kops/s: 1182.59 io_bytes/op: 1440.77 miss_ratio: 0.0185449 max_rss_mb: 1636.45//1597MB 128thread base -> kops/s: 309.91 io_bytes/op: 1438.25 miss_ratio: 0.018399 max_rss_mb: 1689.98/1597MB 128thread folly -> kops/s: 267.605 io_bytes/op: 1394.16 miss_ratio: 0.0180286 max_rss_mb: 1631.91/1597MB 128thread gt_clock -> kops/s: 691.518 io_bytes/op: 9056.73 miss_ratio: 0.0186572 max_rss_mb: 1982.26/1597MB 128thread new_clock -> kops/s: 1406.12 io_bytes/op: 1440.82 miss_ratio: 0.0185463 max_rss_mb: 1685.63//610MB 1thread base -> kops/s: 45.511 io_bytes/op: 2279.61 miss_ratio: 0.0290528 max_rss_mb: 615.137/610MB 1thread folly -> kops/s: 43.386 io_bytes/op: 2217.29 miss_ratio: 0.0289282 max_rss_mb: 600.996/610MB 1thread gt_clock -> kops/s: 46.207 io_bytes/op: 2275.51 miss_ratio: 0.0290057 max_rss_mb: 637.934/610MB 1thread new_clock -> kops/s: 48.879 io_bytes/op: 2283.1 miss_ratio: 0.0291253 max_rss_mb: 613.5//610MB 32thread base -> kops/s: 306.59 io_bytes/op: 2250 miss_ratio: 0.0288721 max_rss_mb: 683.402/610MB 32thread folly -> kops/s: 269.176 io_bytes/op: 2187.86 miss_ratio: 0.0286938 max_rss_mb: 628.742/610MB 32thread gt_clock -> kops/s: 855.097 io_bytes/op: 2279.26 miss_ratio: 0.0288009 max_rss_mb: 733.062/610MB 32thread new_clock -> kops/s: 1121.47 io_bytes/op: 2244.29 miss_ratio: 0.0289046 max_rss_mb: 666.453//610MB 128thread base -> kops/s: 305.079 io_bytes/op: 2252.43 miss_ratio: 0.0288884 max_rss_mb: 723.457/610MB 128thread folly -> kops/s: 269.583 io_bytes/op: 2204.58 miss_ratio: 0.0287001 max_rss_mb: 676.426/610MB 128thread gt_clock -> kops/s: 53.298 io_bytes/op: 8128.98 miss_ratio: 0.0292452 max_rss_mb: 956.273/610MB 128thread new_clock -> kops/s: 1301.09 io_bytes/op: 2246.04 miss_ratio: 0.0289171 max_rss_mb: 788.812//The new version is still winning every time, sometimes dramatically so, and we can tell from the maximum resident memory numbers (which contain some noise, by the way) that the new cache is not cheating on memory usage. IMPORTANT: The previous generation experimental clock cache appears to hit a serious bottleneck in the higher thread count configurations, presumably due to some of its waiting functionality. (The same bottleneck is not seen with partitioned index+filters.)//Now we consider even smaller cache sizes, with higher miss ratios, eviction work, etc.//233MB 1thread base -> kops/s: 10.557 io_bytes/op: 227040 miss_ratio: 0.0403105 max_rss_mb: 247.371/233MB 1thread folly -> kops/s: 15.348 io_bytes/op: 112007 miss_ratio: 0.0372238 max_rss_mb: 245.293/233MB 1thread gt_clock -> kops/s: 6.365 io_bytes/op: 244854 miss_ratio: 0.0413873 max_rss_mb: 259.844/233MB 1thread new_clock -> kops/s: 47.501 io_bytes/op: 2591.93 miss_ratio: 0.0330989 max_rss_mb: 242.461//233MB 32thread base -> kops/s: 96.498 io_bytes/op: 363379 miss_ratio: 0.0459966 max_rss_mb: 479.227/233MB 32thread folly -> kops/s: 109.95 io_bytes/op: 314799 miss_ratio: 0.0450032 max_rss_mb: 400.738/233MB 32thread gt_clock -> kops/s: 2.353 io_bytes/op: 385397 miss_ratio: 0.048445 max_rss_mb: 500.688/233MB 32thread new_clock -> kops/s: 1088.95 io_bytes/op: 2567.02 miss_ratio: 0.0330593 max_rss_mb: 303.402//233MB 128thread base -> kops/s: 84.302 io_bytes/op: 378020 miss_ratio: 0.0466558 max_rss_mb: 1051.84/233MB 128thread folly -> kops/s: 89.921 io_bytes/op: 338242 miss_ratio: 0.0460309 max_rss_mb: 812.785/233MB 128thread gt_clock -> kops/s: 2.588 io_bytes/op: 462833 miss_ratio: 0.0509158 max_rss_mb: 1109.94/233MB 128thread new_clock -> kops/s: 1299.26 io_bytes/op: 2565.94 miss_ratio: 0.0330531 max_rss_mb: 361.016//89MB 1thread base -> kops/s: 0.574 io_bytes/op: 5.35977e+06 miss_ratio: 0.274427 max_rss_mb: 91.3086/89MB 1thread folly -> kops/s: 0.578 io_bytes/op: 5.16549e+06 miss_ratio: 0.27276 max_rss_mb: 96.8984/89MB 1thread gt_clock -> kops/s: 0.512 io_bytes/op: 4.13111e+06 miss_ratio: 0.242817 max_rss_mb: 119.441/89MB 1thread new_clock -> kops/s: 48.172 io_bytes/op: 2709.76 miss_ratio: 0.0346162 max_rss_mb: 100.754//89MB 32thread base -> kops/s: 5.779 io_bytes/op: 6.14192e+06 miss_ratio: 0.320399 max_rss_mb: 311.812/89MB 32thread folly -> kops/s: 5.601 io_bytes/op: 5.83838e+06 miss_ratio: 0.313123 max_rss_mb: 252.418/89MB 32thread gt_clock -> kops/s: 0.77 io_bytes/op: 3.99236e+06 miss_ratio: 0.236296 max_rss_mb: 396.422/89MB 32thread new_clock -> kops/s: 1064.97 io_bytes/op: 2687.23 miss_ratio: 0.0346134 max_rss_mb: 155.293//89MB 128thread base -> kops/s: 4.959 io_bytes/op: 6.20297e+06 miss_ratio: 0.323945 max_rss_mb: 823.43/89MB 128thread folly -> kops/s: 4.962 io_bytes/op: 5.9601e+06 miss_ratio: 0.319857 max_rss_mb: 626.824/89MB 128thread gt_clock -> kops/s: 1.009 io_bytes/op: 4.1083e+06 miss_ratio: 0.242512 max_rss_mb: 1095.32/89MB 128thread new_clock -> kops/s: 1224.39 io_bytes/op: 2688.2 miss_ratio: 0.0346207 max_rss_mb: 218.223//^ Now something interesting has happened: the new clock cache has gained a dramatic lead in the single-threaded case, and this is because the cache is so small, and full filters are so big, that dividing the cache into 64 shards leads to significant (random) imbalances in cache shards and excessive churn in imbalanced shards. This new clock cache only uses two shards for this configuration, and that helps to ensure that entries are part of a sufficiently big pool that their eviction order resembles the single-shard order. (This effect is not seen with partitioned index+filters.)//Even smaller cache size:/34MB 1thread base -> kops/s: 0.198 io_bytes/op: 1.65342e+07 miss_ratio: 0.939466 max_rss_mb: 48.6914/34MB 1thread folly -> kops/s: 0.201 io_bytes/op: 1.63416e+07 miss_ratio: 0.939081 max_rss_mb: 45.3281/34MB 1thread gt_clock -> kops/s: 0.448 io_bytes/op: 4.43957e+06 miss_ratio: 0.266749 max_rss_mb: 100.523/34MB 1thread new_clock -> kops/s: 1.055 io_bytes/op: 1.85439e+06 miss_ratio: 0.107512 max_rss_mb: 75.3125//34MB 32thread base -> kops/s: 3.346 io_bytes/op: 1.64852e+07 miss_ratio: 0.93596 max_rss_mb: 180.48/34MB 32thread folly -> kops/s: 3.431 io_bytes/op: 1.62857e+07 miss_ratio: 0.935693 max_rss_mb: 137.531/34MB 32thread gt_clock -> kops/s: 1.47 io_bytes/op: 4.89704e+06 miss_ratio: 0.295081 max_rss_mb: 392.465/34MB 32thread new_clock -> kops/s: 8.19 io_bytes/op: 3.70456e+06 miss_ratio: 0.20826 max_rss_mb: 519.793//34MB 128thread base -> kops/s: 2.293 io_bytes/op: 1.64351e+07 miss_ratio: 0.931866 max_rss_mb: 449.484/34MB 128thread folly -> kops/s: 2.34 io_bytes/op: 1.6219e+07 miss_ratio: 0.932023 max_rss_mb: 396.457/34MB 128thread gt_clock -> kops/s: 1.798 io_bytes/op: 5.4241e+06 miss_ratio: 0.324881 max_rss_mb: 1104.41/34MB 128thread new_clock -> kops/s: 10.519 io_bytes/op: 2.39354e+06 miss_ratio: 0.136147 max_rss_mb: 1050.52//As the miss ratio gets higher (say, above 10%), the CPU time spent in eviction starts to erode the advantage of using fewer shards (13% miss rate much lower than 94%). LRU's O(1) eviction time can eventually pay off when there's enough block cache churn://13MB 1thread base -> kops/s: 0.195 io_bytes/op: 1.65732e+07 miss_ratio: 0.946604 max_rss_mb: 45.6328/13MB 1thread folly -> kops/s: 0.197 io_bytes/op: 1.63793e+07 miss_ratio: 0.94661 max_rss_mb: 33.8633/13MB 1thread gt_clock -> kops/s: 0.519 io_bytes/op: 4.43316e+06 miss_ratio: 0.269379 max_rss_mb: 100.684/13MB 1thread new_clock -> kops/s: 0.176 io_bytes/op: 1.54148e+07 miss_ratio: 0.91545 max_rss_mb: 66.2383//13MB 32thread base -> kops/s: 3.266 io_bytes/op: 1.65544e+07 miss_ratio: 0.943386 max_rss_mb: 132.492/13MB 32thread folly -> kops/s: 3.396 io_bytes/op: 1.63142e+07 miss_ratio: 0.943243 max_rss_mb: 101.863/13MB 32thread gt_clock -> kops/s: 2.758 io_bytes/op: 5.13714e+06 miss_ratio: 0.310652 max_rss_mb: 396.121/13MB 32thread new_clock -> kops/s: 3.11 io_bytes/op: 1.23419e+07 miss_ratio: 0.708425 max_rss_mb: 321.758//13MB 128thread base -> kops/s: 2.31 io_bytes/op: 1.64823e+07 miss_ratio: 0.939543 max_rss_mb: 425.539/13MB 128thread folly -> kops/s: 2.339 io_bytes/op: 1.6242e+07 miss_ratio: 0.939966 max_rss_mb: 346.098/13MB 128thread gt_clock -> kops/s: 3.223 io_bytes/op: 5.76928e+06 miss_ratio: 0.345899 max_rss_mb: 1087.77/13MB 128thread new_clock -> kops/s: 2.984 io_bytes/op: 1.05341e+07 miss_ratio: 0.606198 max_rss_mb: 898.27//gt_clock is clearly blowing way past its memory budget for lower miss rates and best throughput. new_clock also seems to be exceeding budgets, and this warrants more investigation but is not the use case we are targeting with the new cache. With partitioned index+filter, the miss ratio is much better, and although still high enough that the eviction CPU time is definitely offsetting mutex contention://13MB 1thread base -> kops/s: 16.326 io_bytes/op: 23743.9 miss_ratio: 0.205362 max_rss_mb: 65.2852/13MB 1thread folly -> kops/s: 15.574 io_bytes/op: 19415 miss_ratio: 0.184157 max_rss_mb: 56.3516/13MB 1thread gt_clock -> kops/s: 14.459 io_bytes/op: 22873 miss_ratio: 0.198355 max_rss_mb: 63.9688/13MB 1thread new_clock -> kops/s: 16.34 io_bytes/op: 24386.5 miss_ratio: 0.210512 max_rss_mb: 61.707//13MB 128thread base -> kops/s: 289.786 io_bytes/op: 23710.9 miss_ratio: 0.205056 max_rss_mb: 103.57/13MB 128thread folly -> kops/s: 185.282 io_bytes/op: 19433.1 miss_ratio: 0.184275 max_rss_mb: 116.219/13MB 128thread gt_clock -> kops/s: 354.451 io_bytes/op: 23150.6 miss_ratio: 0.200495 max_rss_mb: 102.871/13MB 128thread new_clock -> kops/s: 295.359 io_bytes/op: 24626.4 miss_ratio: 0.212452 max_rss_mb: 121.109//Pull Request resolved: https://github.com/facebook/rocksdb/pull/10626//Test Plan: updated unit tests, stress/crash test runs including with TSAN, ASAN, UBSAN//Reviewed By: anand1976//Differential Revision: D39368406//Pulled By: pdillinger//fbshipit-source-id: 5afc44da4c656f8f751b44552bbf27bd3ca6fef9",https://github.com/facebook/rocksdb/commit/5724348689c7b6f51a3bbca5723af2185b77653e,6934395,facebook/rocksdb,False,False

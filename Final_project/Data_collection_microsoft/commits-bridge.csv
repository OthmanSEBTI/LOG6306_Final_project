sha,message,html_url,repository_id,repository_full_name,repository_private,repository_fork
49e20f6e7278fa8753a0acf97e55b92f4faffe09,Update content/BCPatterns/event-bridge-pattern/index.md//Co-authored-by: Christian Bräunlich <sundowneffect@gmail.com>,https://github.com/microsoft/alguidelines/commit/49e20f6e7278fa8753a0acf97e55b92f4faffe09,424701451,microsoft/alguidelines,False,False
f516a03c01b82fcc45fec792b5dfd792f9e06a83,Merge pull request #317 from jterry75/simplify_request_return//Simplify the bridge request/return pattern,https://github.com/microsoft/opengcs/commit/f516a03c01b82fcc45fec792b5dfd792f9e06a83,95602435,microsoft/opengcs,False,False
9c3739ba9767038d5af24f37621dc01fba9c477c,"Bridge the CF Collections subproj into NS/- Bridge NS(Mutable)Data, NSCountedSet/- Clean up other collections that were previously bridged/- Add further helper macros for the general class cluster/bridging pattern/- Add unit tests based on the reference platform",https://github.com/microsoft/WinObjC/commit/9c3739ba9767038d5af24f37621dc01fba9c477c,37950166,microsoft/WinObjC,False,False
379e9f63454781bf7cc9900de0dca47a118b23eb,Simplify the bridge request/return pattern//This change makes it easier for the rquest/response pattern to return a result/or error. This is perferred over the w.Write and w.Error pattern where a/response must be written and then an early return. This makes the code easier/to read and control flow easier to understand.,https://github.com/microsoft/opengcs/commit/379e9f63454781bf7cc9900de0dca47a118b23eb,95602435,microsoft/opengcs,False,False
97a7e8bed8f529885cb079904c152883166ddf3a,"Implements the async bridge loop//Implements the async bridge/Implements the bridge multiplexer/Removes any waiting between commands in favor of a channel writer per request/Fixes the ""RegisterExitHook"" pattern in favor of a single channel writer on an async goroutine/Temporarily disables the bridge_test suite put puts in place bridge unit tests. These will be moved when the handler funcs are pulled off of the bridge in the second change.",https://github.com/microsoft/opengcs/commit/97a7e8bed8f529885cb079904c152883166ddf3a,95602435,microsoft/opengcs,False,False
97a7e8bed8f529885cb079904c152883166ddf3a,"Implements the async bridge loop//Implements the async bridge/Implements the bridge multiplexer/Removes any waiting between commands in favor of a channel writer per request/Fixes the ""RegisterExitHook"" pattern in favor of a single channel writer on an async goroutine/Temporarily disables the bridge_test suite put puts in place bridge unit tests. These will be moved when the handler funcs are pulled off of the bridge in the second change.",https://github.com/microsoft/hcsshim/commit/97a7e8bed8f529885cb079904c152883166ddf3a,38258831,microsoft/hcsshim,False,False
e2435d69204c1f041e5742cac9af301021afa46f,"drm/bridge: dw-mipi-dsi.c: Add VPG runtime config through debugfs//Add support for the video pattern generator (VPG) BER pattern mode and/configuration in runtime.//This enables using the debugfs interface to manipulate the VPG after/the pipeline is set./Also, enables the usage of the VPG BER pattern.//Changes in v2:/  - Added VID_MODE_VPG_MODE/  - Solved incompatible return type on __get and __set//Reported-by: kbuild test robot <lkp@intel.com>/Reported-by: Adrian Pop <pop.adrian61@gmail.com>/Signed-off-by: Angelo Ribeiro <angelo.ribeiro@synopsys.com>/Tested-by: Yannick Fertre <yannick.fertre@st.com>/Tested-by: Adrian Pop <pop.adrian61@gmail.com>/Acked-by: Neil Armstrong <narmstrong@baylibre.com>/Cc: Gustavo Pimentel <gustavo.pimentel@synopsys.com>/Cc: Joao Pinto <jpinto@synopsys.com>/Cc: Jose Abreu <jose.abreu@synopsys.com>/Signed-off-by: Neil Armstrong <narmstrong@baylibre.com>/Link: https://patchwork.freedesktop.org/patch/msgid/a809feb7d7153a92e323416f744f1565e995da01.1586180592.git.angelo.ribeiro@synopsys.com",https://github.com/microsoft/WSL2-Linux-Kernel/commit/e2435d69204c1f041e5742cac9af301021afa46f,187922067,microsoft/WSL2-Linux-Kernel,False,False
33f290811d4c1a09c4e92f5bf0458525835dbcba,drm/bridge: dw-mipi-dsi: Use kmemdup cf. kmalloc+memcpy//kmemdup can be used instead of kmalloc+memcpy. Replace an occurrence of/this pattern.//Issue identified with Coccinelle.//Signed-off-by: Alex Dewar <alex.dewar90@gmail.com>/Acked-by: Neil Armstrong <narmstrong@baylibre.com>/Signed-off-by: Neil Armstrong <narmstrong@baylibre.com>/Link: https://patchwork.freedesktop.org/patch/msgid/20200909190213.156302-1-alex.dewar90@gmail.com,https://github.com/microsoft/WSL2-Linux-Kernel/commit/33f290811d4c1a09c4e92f5bf0458525835dbcba,187922067,microsoft/WSL2-Linux-Kernel,False,False
bfe8136caf389c2c306e83663c43926ae1ee6230,"Adjust strategy for bridging to work better for mutability//Description:/Instead of doing object substitution on alloc, move to doing it on init./This pattern is a bit more convoluted but allows us to correctly differentiate between mutable and immutable/calls in the concrete classes.//How verified:/UTs for NSArray and NSDictionary pass//Reviewed-by: jihua",https://github.com/microsoft/WinObjC/commit/bfe8136caf389c2c306e83663c43926ae1ee6230,37950166,microsoft/WinObjC,False,False
0adda1e4d47a836275fb0baabf98c402759f385f,"[x86] Adjust the patterns for lowering X86vzmovl nodes which don't/perform a load to use blendps rather than movss when it is available.//For non-loads, blendps is *much* faster. It can execute on two ports in/Sandy Bridge and Ivy Bridge, and *three* ports on Haswell. This fixes/one of the ""regressions"" from aggressively taking the ""insertion"" path/in the new vector shuffle lowering.//This does highlight one problem with blendps -- it isn't commuted as/heavily as it should be. That's future work though.//llvm-svn: 219022",https://github.com/microsoft/checkedc-clang/commit/0adda1e4d47a836275fb0baabf98c402759f385f,60645050,microsoft/checkedc-clang,False,False
91ea3e41ae46348d520e9cdf8123748d01b2a46a,"[x86] Adjust the patterns for lowering X86vzmovl nodes which don't/perform a load to use blendps rather than movss when it is available.//For non-loads, blendps is *much* faster. It can execute on two ports in/Sandy Bridge and Ivy Bridge, and *three* ports on Haswell. This fixes/one of the ""regressions"" from aggressively taking the ""insertion"" path/in the new vector shuffle lowering.//This does highlight one problem with blendps -- it isn't commuted as/heavily as it should be. That's future work though.//git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@219022 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/llvm/commit/91ea3e41ae46348d520e9cdf8123748d01b2a46a,29704274,microsoft/llvm,False,False
91ea3e41ae46348d520e9cdf8123748d01b2a46a,"[x86] Adjust the patterns for lowering X86vzmovl nodes which don't/perform a load to use blendps rather than movss when it is available.//For non-loads, blendps is *much* faster. It can execute on two ports in/Sandy Bridge and Ivy Bridge, and *three* ports on Haswell. This fixes/one of the ""regressions"" from aggressively taking the ""insertion"" path/in the new vector shuffle lowering.//This does highlight one problem with blendps -- it isn't commuted as/heavily as it should be. That's future work though.//git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@219022 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/checkedc-llvm/commit/91ea3e41ae46348d520e9cdf8123748d01b2a46a,60644745,microsoft/checkedc-llvm,False,False
da8446b8337733b8bc6e14155805cad3087598a1,"X86: Custom lower zext v16i8 to v16i16.//On sandy bridge (PR17654) we now get/	vpxor	%xmm1, %xmm1, %xmm1/	vpunpckhbw	%xmm1, %xmm0, %xmm2/	vpunpcklbw	%xmm1, %xmm0, %xmm0/	vinsertf128	$1, %xmm2, %ymm0, %ymm0//On haswell it's a simple/	vpmovzxbw	%xmm0, %ymm0//There is a maze of duplicated and dead transforms and patterns in this/area. Remove the dead custom lowering of zext v8i16 to v8i32, that's/already handled by LowerAVXExtend.//llvm-svn: 193262",https://github.com/microsoft/checkedc-clang/commit/da8446b8337733b8bc6e14155805cad3087598a1,60645050,microsoft/checkedc-clang,False,False
7377cff9e7641c75678fd5c80472942fd7ef869a,"X86: Custom lower zext v16i8 to v16i16.//On sandy bridge (PR17654) we now get/	vpxor	%xmm1, %xmm1, %xmm1/	vpunpckhbw	%xmm1, %xmm0, %xmm2/	vpunpcklbw	%xmm1, %xmm0, %xmm0/	vinsertf128	$1, %xmm2, %ymm0, %ymm0//On haswell it's a simple/	vpmovzxbw	%xmm0, %ymm0//There is a maze of duplicated and dead transforms and patterns in this/area. Remove the dead custom lowering of zext v8i16 to v8i32, that's/already handled by LowerAVXExtend.//git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@193262 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/llvm/commit/7377cff9e7641c75678fd5c80472942fd7ef869a,29704274,microsoft/llvm,False,False
7377cff9e7641c75678fd5c80472942fd7ef869a,"X86: Custom lower zext v16i8 to v16i16.//On sandy bridge (PR17654) we now get/	vpxor	%xmm1, %xmm1, %xmm1/	vpunpckhbw	%xmm1, %xmm0, %xmm2/	vpunpcklbw	%xmm1, %xmm0, %xmm0/	vinsertf128	$1, %xmm2, %ymm0, %ymm0//On haswell it's a simple/	vpmovzxbw	%xmm0, %ymm0//There is a maze of duplicated and dead transforms and patterns in this/area. Remove the dead custom lowering of zext v8i16 to v8i32, that's/already handled by LowerAVXExtend.//git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@193262 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/checkedc-llvm/commit/7377cff9e7641c75678fd5c80472942fd7ef869a,60644745,microsoft/checkedc-llvm,False,False
d46700e109ffef34429773f143073aac01025a55,"[XLA] Disambiguate reshape's dynamic output dimension when output is decomposed by input.//This is used as a hint for dynamic dimension inference to to know/which dimension is inferred by upper level framework. The problem it/tries to solve is this pattern that the pass sees://  [<=20]       // 20 is dynamic/   |  Reshape/  [1, 20]    // which is dynamic?//Originally we say if the dimension 20 is unchanged, then in the result shape 20 is dynamic.//However, in some models we see this mirror pattern://  [<=1, 20]    // 1 is dynamic/   |  Reshape/  [20]       // 20 is dynamic/   |  Reshape/  [<=1, 20]    // 1 is dynamic//As one can see, both ""1"" and ""20"" can be a valid dynamic dimension when reshaping from [20] to [1, 20]. It/is hard to tell which result dimension is dynamic without a hint.//There are three things we need in order to disambiguate://1. A new ""inferred_dimensino"" field ./This CL pump through a new field ""inferred dimension"" through bridge/to HLO as a hint for the dynamic_dimension_inference pass to know/which dimension in the result is dynamic in reshape.//2. A simple constraint system that encodes how the dynamic dimension is generated in the first place./See comments in dynamic_dimension_inference.h and dynamic_dimension_inference.cc//PiperOrigin-RevId: 255696421",https://github.com/microsoft/tensorflow-directml/commit/d46700e109ffef34429773f143073aac01025a55,291217084,microsoft/tensorflow-directml,False,False
93b6e016b182e1d103ddfec7a5844dc02958a3af,"[CodeGenPrepare] Move sign/zero extensions near loads using type promotion.//This patch extends the optimization in CodeGenPrepare that moves a sign/zero/extension near a load when the target can combine them. The optimization may/promote any operations between the extension and the load to make that possible.//Although this optimization may be beneficial for all targets, in particular/AArch64, this is enabled for X86 only as I have not benchmarked it for other/targets yet.///** Context **//Most targets feature extended loads, i.e., loads that perform a zero or sign/extension for free. In that context it is interesting to expose such pattern in/CodeGenPrepare so that the instruction selection pass can form such loads./Sometimes, this pattern is blocked because of instructions between the load and/the extension. When those instructions are promotable to the extended type, we/can expose this pattern.///** Motivating Example **//Let us consider an example:/define void @foo(i8* %addr1, i32* %addr2, i8 %a, i32 %b) {/  %ld = load i8* %addr1/  %zextld = zext i8 %ld to i32/  %ld2 = load i32* %addr2/  %add = add nsw i32 %ld2, %zextld/  %sextadd = sext i32 %add to i64/  %zexta = zext i8 %a to i32/  %addza = add nsw i32 %zexta, %zextld/  %sextaddza = sext i32 %addza to i64/  %addb = add nsw i32 %b, %zextld/  %sextaddb = sext i32 %addb to i64/  call void @dummy(i64 %sextadd, i64 %sextaddza, i64 %sextaddb)/  ret void/}//As it is, this IR generates the following assembly on x86_64:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movl  (%rsi), %es      # plain load/  addl  %eax, %esi       # 32-bit add/  movslq  %esi, %rdi     # sign extend the result of add/  movzbl  %dl, %edx      # zero extend the first argument/  addl  %eax, %edx       # 32-bit add/  movslq  %edx, %rsi     # sign extend the result of add/  addl  %eax, %ecx       # 32-bit add/  movslq  %ecx, %rdx     # sign extend the result of add/[...]/The throughput of this sequence is 7.45 cycles on Ivy Bridge according to IACA.//Now, by promoting the additions to form more extended loads we would generate:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movslq  (%rsi), %rdi   # sign-extended load/  addq  %rax, %rdi       # 64-bit add/  movzbl  %dl, %esi      # zero extend the first argument/  addq  %rax, %rsi       # 64-bit add/  movslq  %ecx, %rdx     # sign extend the second argument/  addq  %rax, %rdx       # 64-bit add/[...]/The throughput of this sequence is 6.15 cycles on Ivy Bridge according to IACA.//This kind of sequences happen a lot on code using 32-bit indexes on 64-bit/architectures.//Note: The throughput numbers are similar on Sandy Bridge and Haswell.///** Proposed Solution **//To avoid the penalty of all these sign/zero extensions, we merge them in the/loads at the beginning of the chain of computation by promoting all the chain of/computation on the extended type. The promotion is done if and only if we do not/introduce new extensions, i.e., if we do not degrade the code quality./To achieve this, we extend the existing “move ext to load” optimization with the/promotion mechanism introduced to match larger patterns for addressing mode/(r200947)./The idea of this extension is to perform the following transformation:/ext(promotableInst1(...(promotableInstN(load))))/=>/promotedInst1(...(promotedInstN(ext(load))))//The promotion mechanism in that optimization is enabled by a new TargetLowering/switch, which is off by default. In other words, by default, the optimization/performs the “move ext to load” optimization as it was before this patch.///** Performance **//Configuration: x86_64: Ivy Bridge fixed at 2900MHz running OS X 10.10./Tested Optimization Levels: O3/Os/Tests: llvm-testsuite + externals./Results:/- No regression beside noise./- Improvements:/CINT2006/473.astar:  ~2%/Benchmarks/PAQ8p: ~2%/Misc/perlin: ~3%//The results are consistent for both O3 and Os.//<rdar://problem/18310086>///git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@224351 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/llvm/commit/93b6e016b182e1d103ddfec7a5844dc02958a3af,29704274,microsoft/llvm,False,False
fc2201e922261d1c21bfe68fb205de6a13b1f18e,"[CodeGenPrepare] Reapply r224351 with a fix for the assertion failure:/The type promotion helper does not support vector type, so when make/such it does not kick in in such cases.//Original commit message:/[CodeGenPrepare] Move sign/zero extensions near loads using type promotion.//This patch extends the optimization in CodeGenPrepare that moves a sign/zero/extension near a load when the target can combine them. The optimization may/promote any operations between the extension and the load to make that possible.//Although this optimization may be beneficial for all targets, in particular/AArch64, this is enabled for X86 only as I have not benchmarked it for other/targets yet.///** Context **//Most targets feature extended loads, i.e., loads that perform a zero or sign/extension for free. In that context it is interesting to expose such pattern in/CodeGenPrepare so that the instruction selection pass can form such loads./Sometimes, this pattern is blocked because of instructions between the load and/the extension. When those instructions are promotable to the extended type, we/can expose this pattern.///** Motivating Example **//Let us consider an example:/define void @foo(i8* %addr1, i32* %addr2, i8 %a, i32 %b) {/  %ld = load i8* %addr1/  %zextld = zext i8 %ld to i32/  %ld2 = load i32* %addr2/  %add = add nsw i32 %ld2, %zextld/  %sextadd = sext i32 %add to i64/  %zexta = zext i8 %a to i32/  %addza = add nsw i32 %zexta, %zextld/  %sextaddza = sext i32 %addza to i64/  %addb = add nsw i32 %b, %zextld/  %sextaddb = sext i32 %addb to i64/  call void @dummy(i64 %sextadd, i64 %sextaddza, i64 %sextaddb)/  ret void/}//As it is, this IR generates the following assembly on x86_64:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movl  (%rsi), %es      # plain load/  addl  %eax, %esi       # 32-bit add/  movslq  %esi, %rdi     # sign extend the result of add/  movzbl  %dl, %edx      # zero extend the first argument/  addl  %eax, %edx       # 32-bit add/  movslq  %edx, %rsi     # sign extend the result of add/  addl  %eax, %ecx       # 32-bit add/  movslq  %ecx, %rdx     # sign extend the result of add/[...]/The throughput of this sequence is 7.45 cycles on Ivy Bridge according to IACA.//Now, by promoting the additions to form more extended loads we would generate:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movslq  (%rsi), %rdi   # sign-extended load/  addq  %rax, %rdi       # 64-bit add/  movzbl  %dl, %esi      # zero extend the first argument/  addq  %rax, %rsi       # 64-bit add/  movslq  %ecx, %rdx     # sign extend the second argument/  addq  %rax, %rdx       # 64-bit add/[...]/The throughput of this sequence is 6.15 cycles on Ivy Bridge according to IACA.//This kind of sequences happen a lot on code using 32-bit indexes on 64-bit/architectures.//Note: The throughput numbers are similar on Sandy Bridge and Haswell.///** Proposed Solution **//To avoid the penalty of all these sign/zero extensions, we merge them in the/loads at the beginning of the chain of computation by promoting all the chain of/computation on the extended type. The promotion is done if and only if we do not/introduce new extensions, i.e., if we do not degrade the code quality./To achieve this, we extend the existing “move ext to load” optimization with the/promotion mechanism introduced to match larger patterns for addressing mode/(r200947)./The idea of this extension is to perform the following transformation:/ext(promotableInst1(...(promotableInstN(load))))/=>/promotedInst1(...(promotedInstN(ext(load))))//The promotion mechanism in that optimization is enabled by a new TargetLowering/switch, which is off by default. In other words, by default, the optimization/performs the “move ext to load” optimization as it was before this patch.///** Performance **//Configuration: x86_64: Ivy Bridge fixed at 2900MHz running OS X 10.10./Tested Optimization Levels: O3/Os/Tests: llvm-testsuite + externals./Results:/- No regression beside noise./- Improvements:/CINT2006/473.astar:  ~2%/Benchmarks/PAQ8p: ~2%/Misc/perlin: ~3%//The results are consistent for both O3 and Os.//<rdar://problem/18310086>//llvm-svn: 224402",https://github.com/microsoft/checkedc-clang/commit/fc2201e922261d1c21bfe68fb205de6a13b1f18e,60645050,microsoft/checkedc-clang,False,False
d5e57b731f60609c9bd559bd63df4e0830e805a8,"[CodeGenPrepare] Move sign/zero extensions near loads using type promotion.//This patch extends the optimization in CodeGenPrepare that moves a sign/zero/extension near a load when the target can combine them. The optimization may/promote any operations between the extension and the load to make that possible.//Although this optimization may be beneficial for all targets, in particular/AArch64, this is enabled for X86 only as I have not benchmarked it for other/targets yet.///** Context **//Most targets feature extended loads, i.e., loads that perform a zero or sign/extension for free. In that context it is interesting to expose such pattern in/CodeGenPrepare so that the instruction selection pass can form such loads./Sometimes, this pattern is blocked because of instructions between the load and/the extension. When those instructions are promotable to the extended type, we/can expose this pattern.///** Motivating Example **//Let us consider an example:/define void @foo(i8* %addr1, i32* %addr2, i8 %a, i32 %b) {/  %ld = load i8* %addr1/  %zextld = zext i8 %ld to i32/  %ld2 = load i32* %addr2/  %add = add nsw i32 %ld2, %zextld/  %sextadd = sext i32 %add to i64/  %zexta = zext i8 %a to i32/  %addza = add nsw i32 %zexta, %zextld/  %sextaddza = sext i32 %addza to i64/  %addb = add nsw i32 %b, %zextld/  %sextaddb = sext i32 %addb to i64/  call void @dummy(i64 %sextadd, i64 %sextaddza, i64 %sextaddb)/  ret void/}//As it is, this IR generates the following assembly on x86_64:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movl  (%rsi), %es      # plain load/  addl  %eax, %esi       # 32-bit add/  movslq  %esi, %rdi     # sign extend the result of add/  movzbl  %dl, %edx      # zero extend the first argument/  addl  %eax, %edx       # 32-bit add/  movslq  %edx, %rsi     # sign extend the result of add/  addl  %eax, %ecx       # 32-bit add/  movslq  %ecx, %rdx     # sign extend the result of add/[...]/The throughput of this sequence is 7.45 cycles on Ivy Bridge according to IACA.//Now, by promoting the additions to form more extended loads we would generate:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movslq  (%rsi), %rdi   # sign-extended load/  addq  %rax, %rdi       # 64-bit add/  movzbl  %dl, %esi      # zero extend the first argument/  addq  %rax, %rsi       # 64-bit add/  movslq  %ecx, %rdx     # sign extend the second argument/  addq  %rax, %rdx       # 64-bit add/[...]/The throughput of this sequence is 6.15 cycles on Ivy Bridge according to IACA.//This kind of sequences happen a lot on code using 32-bit indexes on 64-bit/architectures.//Note: The throughput numbers are similar on Sandy Bridge and Haswell.///** Proposed Solution **//To avoid the penalty of all these sign/zero extensions, we merge them in the/loads at the beginning of the chain of computation by promoting all the chain of/computation on the extended type. The promotion is done if and only if we do not/introduce new extensions, i.e., if we do not degrade the code quality./To achieve this, we extend the existing “move ext to load” optimization with the/promotion mechanism introduced to match larger patterns for addressing mode/(r200947)./The idea of this extension is to perform the following transformation:/ext(promotableInst1(...(promotableInstN(load))))/=>/promotedInst1(...(promotedInstN(ext(load))))//The promotion mechanism in that optimization is enabled by a new TargetLowering/switch, which is off by default. In other words, by default, the optimization/performs the “move ext to load” optimization as it was before this patch.///** Performance **//Configuration: x86_64: Ivy Bridge fixed at 2900MHz running OS X 10.10./Tested Optimization Levels: O3/Os/Tests: llvm-testsuite + externals./Results:/- No regression beside noise./- Improvements:/CINT2006/473.astar:  ~2%/Benchmarks/PAQ8p: ~2%/Misc/perlin: ~3%//The results are consistent for both O3 and Os.//<rdar://problem/18310086>//llvm-svn: 224351",https://github.com/microsoft/checkedc-clang/commit/d5e57b731f60609c9bd559bd63df4e0830e805a8,60645050,microsoft/checkedc-clang,False,False
93b6e016b182e1d103ddfec7a5844dc02958a3af,"[CodeGenPrepare] Move sign/zero extensions near loads using type promotion.//This patch extends the optimization in CodeGenPrepare that moves a sign/zero/extension near a load when the target can combine them. The optimization may/promote any operations between the extension and the load to make that possible.//Although this optimization may be beneficial for all targets, in particular/AArch64, this is enabled for X86 only as I have not benchmarked it for other/targets yet.///** Context **//Most targets feature extended loads, i.e., loads that perform a zero or sign/extension for free. In that context it is interesting to expose such pattern in/CodeGenPrepare so that the instruction selection pass can form such loads./Sometimes, this pattern is blocked because of instructions between the load and/the extension. When those instructions are promotable to the extended type, we/can expose this pattern.///** Motivating Example **//Let us consider an example:/define void @foo(i8* %addr1, i32* %addr2, i8 %a, i32 %b) {/  %ld = load i8* %addr1/  %zextld = zext i8 %ld to i32/  %ld2 = load i32* %addr2/  %add = add nsw i32 %ld2, %zextld/  %sextadd = sext i32 %add to i64/  %zexta = zext i8 %a to i32/  %addza = add nsw i32 %zexta, %zextld/  %sextaddza = sext i32 %addza to i64/  %addb = add nsw i32 %b, %zextld/  %sextaddb = sext i32 %addb to i64/  call void @dummy(i64 %sextadd, i64 %sextaddza, i64 %sextaddb)/  ret void/}//As it is, this IR generates the following assembly on x86_64:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movl  (%rsi), %es      # plain load/  addl  %eax, %esi       # 32-bit add/  movslq  %esi, %rdi     # sign extend the result of add/  movzbl  %dl, %edx      # zero extend the first argument/  addl  %eax, %edx       # 32-bit add/  movslq  %edx, %rsi     # sign extend the result of add/  addl  %eax, %ecx       # 32-bit add/  movslq  %ecx, %rdx     # sign extend the result of add/[...]/The throughput of this sequence is 7.45 cycles on Ivy Bridge according to IACA.//Now, by promoting the additions to form more extended loads we would generate:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movslq  (%rsi), %rdi   # sign-extended load/  addq  %rax, %rdi       # 64-bit add/  movzbl  %dl, %esi      # zero extend the first argument/  addq  %rax, %rsi       # 64-bit add/  movslq  %ecx, %rdx     # sign extend the second argument/  addq  %rax, %rdx       # 64-bit add/[...]/The throughput of this sequence is 6.15 cycles on Ivy Bridge according to IACA.//This kind of sequences happen a lot on code using 32-bit indexes on 64-bit/architectures.//Note: The throughput numbers are similar on Sandy Bridge and Haswell.///** Proposed Solution **//To avoid the penalty of all these sign/zero extensions, we merge them in the/loads at the beginning of the chain of computation by promoting all the chain of/computation on the extended type. The promotion is done if and only if we do not/introduce new extensions, i.e., if we do not degrade the code quality./To achieve this, we extend the existing “move ext to load” optimization with the/promotion mechanism introduced to match larger patterns for addressing mode/(r200947)./The idea of this extension is to perform the following transformation:/ext(promotableInst1(...(promotableInstN(load))))/=>/promotedInst1(...(promotedInstN(ext(load))))//The promotion mechanism in that optimization is enabled by a new TargetLowering/switch, which is off by default. In other words, by default, the optimization/performs the “move ext to load” optimization as it was before this patch.///** Performance **//Configuration: x86_64: Ivy Bridge fixed at 2900MHz running OS X 10.10./Tested Optimization Levels: O3/Os/Tests: llvm-testsuite + externals./Results:/- No regression beside noise./- Improvements:/CINT2006/473.astar:  ~2%/Benchmarks/PAQ8p: ~2%/Misc/perlin: ~3%//The results are consistent for both O3 and Os.//<rdar://problem/18310086>///git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@224351 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/checkedc-llvm/commit/93b6e016b182e1d103ddfec7a5844dc02958a3af,60644745,microsoft/checkedc-llvm,False,False
a765c28db3199f9511e1206d1addc3621d688cff,"A simple testing framework for lldb using python's unit testing framework.//Tests for lldb are written as python scripts which take advantage of the script/bridging provided by LLDB.framework to interact with lldb core.//A specific naming pattern is followed by the .py script to be recognized as/a module which implements a test scenario, namely, Test*.py.//To specify the directories where ""Test*.py"" python test scripts are located,/you need to pass in a list of directory names.  By default, the current/working directory is searched if nothing is specified on the command line.//An example://[14:10:20] johnny:/Volumes/data/lldb/svn/trunk/test $ ./dotest.py -v example/test_choice (TestSequenceFunctions.TestSequenceFunctions) ... ok/test_sample (TestSequenceFunctions.TestSequenceFunctions) ... ok/test_shuffle (TestSequenceFunctions.TestSequenceFunctions) ... ok//----------------------------------------------------------------------/Ran 3 tests in 0.000s//OK//llvm-svn: 106890",https://github.com/microsoft/checkedc-clang/commit/a765c28db3199f9511e1206d1addc3621d688cff,60645050,microsoft/checkedc-clang,False,False
9f4c2cffd08c102107992cd01c12c4a53475baf6,"Merge branch 'mlxsw-Un-offload-FDB-on-NVE-detach-attach'//Ido Schimmel says://====================/mlxsw: Un/offload FDB on NVE detach/attach//Petr says://When a VXLAN device is attached to a bridge of a driver capable of/offloading such, or upped, the FDB entries already present at the device/need to be offloaded. Similarly when an offloaded VXLAN device ceases/being interesting (it is downed, or detached, or a front-panel port/netdevice is detached from the bridge that the VXLAN device is attached/to), any offloaded FDB entries need to be unoffloaded and unmarked. This/attach / detach processing is implemented in this patchset.//In patch #1, a code pattern is extracted into a named function for/easier reuse.//In patch #2, vxlan_fdb_replay() is added to send/SWITCHDEV_VXLAN_FDB_ADD_TO_DEVICE for each FDB entry with a given VNI./The intention is that the offloading driver will interpret these events/like any other and thus offload the FDB entries that existed prior to/VXLAN attach.//In patches #3 and #4, the functions vxlan_fdb_clear_offload() resp./br_fdb_clear_offload() are added. These clear the offloaded flag at/matching FDB entries.//In patches #5-#9, we introduce FID-type-specific and NVE-type-specific/ops necessary to properly abstract invocations of the replay/clear/functions.//Finally patch #10 implements the FDB management.//In patch #11, the mlxsw-specific test case is extended to check that the/management of offload marks under the newly-supported situations is/correct. Patch #12, from Ido, exercises the new code paths in actual/functional test.//v2:/- Patch #1:/    - Modify vxlan_fdb_switchdev_notifier_info() to initialize the/      structure through a passed-in pointer argument, instead of returning/      it as a value./- Patch #2:/    - Adapt to API change in vxlan_fdb_switchdev_notifier_info()/====================//Signed-off-by: David S. Miller <davem@davemloft.net>",https://github.com/microsoft/WSL2-Linux-Kernel/commit/9f4c2cffd08c102107992cd01c12c4a53475baf6,187922067,microsoft/WSL2-Linux-Kernel,False,False
3ce406bda027dacffcb3f9cfc6455c6d8314751e,"Merge branch 'net-marvell-prestera-Add-Switchdev-driver-for-Prestera-family-ASIC-device-98DX3255-AC3x'//Vadym Kochan says://====================/net: marvell: prestera: Add Switchdev driver for Prestera family ASIC device 98DX3255 (AC3x)//Marvell Prestera 98DX3255 integrates up to 24 ports of 1GbE with 8/ports of 10GbE uplinks or 2 ports of 40Gbps stacking for a largely/wireless SMB deployment.//Prestera Switchdev is a firmware based driver that operates via PCI bus.  The/current implementation supports only boards designed for the Marvell Switchdev/solution and requires special firmware.//This driver implementation includes only L1, basic L2 support, and RX/TX.//The core Prestera switching logic is implemented in prestera_main.c, there is/an intermediate hw layer between core logic and firmware. It is/implemented in prestera_hw.c, the purpose of it is to encapsulate hw/related logic, in future there is a plan to support more devices with/different HW related configurations.//The following Switchdev features are supported://    - VLAN-aware bridge offloading/    - VLAN-unaware bridge offloading/    - FDB offloading (learning, ageing)/    - Switchport configuration//The original firmware image is uploaded to the linux-firmware repository.//PATCH v9:/    1) Replace read_poll_timeout_atomic() by original 'do {} while()' loop/       because it works much better than read_poll_timeout_atomic()/       considering the TX rate. Also it fixes warning reported on v8.//    2) Use ENOENT instead of EEXIST when item is not found in few/       places - prestera_hw.c and prestera_rxtx.c//    Patches updated:/        [1] net: marvell: prestera: Add driver for Prestera family ASIC devices//PATCH v8:/    1) Put license in one line.//    2) Sort includes.//    3) Add missing comma for last enum member//    4) Return original error code from last called func/       in places where instead other error code was used.//    5) Add comma for last member in initialized struct in prestera_hw.c//    6) Do not initialize 'int err = 0' where it is not needed.//    7) Simplify device-tree ""marvell,prestera"" node parsing by removing not/       needed checking on 'np == NULL'.//    8) Use u32p_replace_bits() instead of open-coded ((word & ~mask) | val)//    9) Use dev_warn_ratelimited() instead of pr_warn_ratelimited to indicate the device/        instance in prestera_rxtx.c//    10) Simplify circular buffer list creation in prestera_sdma_{rx,tx}_init() by using/        do { } while (prev != tail) construction.//    11) Use MSEC_PER_SEC instead of hard-coded 1000.//    12) Use traditional error handling pattern://       err = F();/       if (err)/           return err;//    13) Use ether_addr_copy() instead of memcpy() for mac FDB copying in prestera_hw.c//    14) Drop swdev->ageing_time member which is not used.//    15) Fix ageing macro to be in ms instead of seconds.//    Patches updated:/        [1] net: marvell: prestera: Add driver for Prestera family ASIC devices/	[2] net: marvell: prestera: Add PCI interface support/        [3] net: marvell: prestera: Add basic devlink support/	[4] net: marvell: prestera: Add ethtool interface support/	[5] net: marvell: prestera: Add Switchdev driver implementation//PATCH v7:/    1) Use ether_addr_copy() in prestera_main.c:prestera_port_set_mac_address()/       instead of memcpy().//    2) Removed not needed device's DMA address range check on/       dma_pool_alloc() in prestera_rxtx.c:prestera_sdma_buf_init(),/       this should be handled by dma_xxx() API considerig device's DMA mask.//    3) Removed not needed device's DMA address range check on/       dma_map_single() in prestera_rxtx.c:prestera_sdma_rx_skb_alloc(),/       this should be handled by dma_xxx() API considerig device's DMA mask.//    4) Add comment about port mac address limitation in the code where/       it is used and checked - prestera_main.c://           - prestera_is_valid_mac_addr()/           - prestera_port_create()//    5) Add missing destroy_workqueue(swdev_wq) in prestera_switchdev.c:prestera_switchdev_init()/       on error path handling.//    Patches updated:/        [1] net: marvell: prestera: Add driver for Prestera family ASIC devices/        [5] net: marvell: prestera: Add Switchdev driver implementation//PATCH v6:/    1) Use rwlock to protect port list on create/delete stages. The list/       is mostly readable by fw event handler or packets receiver, but/       updated only on create/delete port which are performed on switch init/fini/       stages.//    2) Remove not needed variable initialization in prestera_dsa.c:prestera_dsa_parse()//    3) Get rid of bounce buffer used by tx handler in prestera_rxtx.c,/       the bounce buffer should be handled by dma_xxx API via swiotlb.//    4) Fix PRESTERA_SDMA_RX_DESC_PKT_LEN macro by using correct GENMASK(13, 0) in prestera_rxtx.c//    Patches updated:/        [1] net: marvell: prestera: Add driver for Prestera family ASIC devices//PATCH v5:/    0) add Co-developed tags for people who was involved in development.//    1) Make SPDX license as separate comment//    2) Change 'u8 *' -> 'void *', It allows to avoid not-needed u8* casting.//    3) Remove "","" in terminated enum's.//    4) Use GENMASK(end, start) where it is applicable in.//    5) Remove not-needed 'u8 *' casting.//    6) Apply common error-check pattern//    7) Use ether_addr_copy instead of memcpy//    8) Use define for maximum MAC address range (255)//    9) Simplify prestera_port_state_set() in prestera_main.c by/       using separate if-blocks for state setting://        if (is_up) {/        .../        } else {/        .../        }//      which makes logic more understandable.//    10) Simplify sdma tx wait logic when checking/updating tx_ring->burst.//    11) Remove not-needed packed & aligned attributes//    12) Use USEC_PER_MSEC as multiplier when converting ms -> usec on calling/        readl_poll_timeout.//    13) Simplified some error path handling by simple return error code in.//    14) Remove not-needed err assignment in.//    15) Use dev_err() in prestera_devlink_register(...).//    Patches updated:/        [1] net: marvell: prestera: Add driver for Prestera family ASIC devices/	[2] net: marvell: prestera: Add PCI interface support/        [3] net: marvell: prestera: Add basic devlink support/	[4] net: marvell: prestera: Add ethtool interface support/	[5] net: marvell: prestera: Add Switchdev driver implementation//PATCH v4:/    1) Use prestera_ prefix in netdev_ops variable.//    2) Kconfig: use 'default PRESTERA' build type for CONFIG_PRESTERA_PCI to be/       synced by default with prestera core module.//    3) Use memcpy_xxio helpers in prestera_pci.c for IO buffer copying.//    4) Generate fw image path via snprintf() instead of macroses.//    5) Use pcim_ helpers in prestera_pci.c which simplified the/       probe/remove logic.//    6) Removed not needed initializations of variables which are used in/       readl_poll_xxx() helpers.//    7) Fixed few grammar mistakes in patch[2] description.//    8) Export only prestera_ethtool_ops struct instead of each/       ethtool handler.//    9) Add check for prestera_dev_check() in switchdev event handling to/       make sure there is no wrong topology.//    Patches updated:/        [1] net: marvell: prestera: Add driver for Prestera family ASIC devices/	[2] net: marvell: prestera: Add PCI interface support/	[4] net: marvell: prestera: Add ethtool interface support/	[5] net: marvell: prestera: Add Switchdev driver implementation//PATCH v3:/    1) Simplify __be32 type casting in prestera_dsa.c//    2) Added per-patch changelog under ""---"" line.//PATCH v2:/    1) Use devlink_port_type_clear()//    2) Add _MS prefix to timeout defines.//    3) Remove not-needed packed attribute from the firmware ipc structs,/       also the firmware image needs to be uploaded too (will do it soon).//    4) Introduce prestera_hw_switch_fini(), to be mirrored with init and/       do simple validation if the event handlers are unregistered.//    5) Use kfree_rcu() for event handler unregistering.//    6) Get rid of rcu-list usage when dealing with ports, not needed for/       now.//    7) Little spelling corrections in the error/info messages.//    8) Make pci probe & remove logic mirrored.//    9) Get rid of ETH_FCS_LEN in headroom setting, not needed.//PATCH:/    1) Fixed W=1 warnings//    2) Renamed PCI driver name to be more generic ""Prestera DX"" because/       there will be more devices supported.//    3) Changed firmware image dir path: marvell/ -> mrvl/prestera//       to be aligned with location in linux-firmware.git (if such/       will be accepted).//RFC v3:/    1) Fix prestera prefix in prestera_rxtx.c//    2) Protect concurrent access from multiple ports on multiple CPU system/       on tx path by spinlock in prestera_rxtx.c//    3) Try to get base mac address from device-tree, otherwise use a random generated one.//    4) Move ethtool interface support into separate prestera_ethtool.c file.//    5) Add basic devlink support and get rid of physical port naming ops.//    6) Add STP support in Switchdev driver.//    7) Removed MODULE_AUTHOR//    8) Renamed prestera.c -> prestera_main.c, and kernel module to/       prestera.ko//RFC v2:/    1) Use ""pestera_"" prefix in struct's and functions instead of mvsw_pr_//    2) Original series split into additional patches for Switchdev ethtool support.//    3) Use major and minor firmware version numbers in the firmware image filename.//    4) Removed not needed prints.//    5) Use iopoll API for waiting on register's value in prestera_pci.c//    6) Use standart approach for describing PCI ID matching section instead of using/       custom wrappers in prestera_pci.c//    7) Add RX/TX support in prestera_rxtx.c.//    8) Rewritten prestera_switchdev.c with following changes:/       - handle netdev events from prestera.c//       - use struct prestera_bridge for bridge objects, and get rid of/         struct prestera_bridge_device which may confuse.//       - use refcount_t//    9) Get rid of macro usage for sending fw requests in prestera_hw.c//    10) Add base_mac setting as module parameter. base_mac is required for/        generation default port's mac./====================//Signed-off-by: David S. Miller <davem@davemloft.net>",https://github.com/microsoft/WSL2-Linux-Kernel/commit/3ce406bda027dacffcb3f9cfc6455c6d8314751e,187922067,microsoft/WSL2-Linux-Kernel,False,False
7a56493f0620cc1b4cffc9bc59289fdefe76b5f3,"Merge branch 'netdev-altnames'//Jiri Pirko says://====================/net: introduce alternative names for network interfaces//In the past, there was repeatedly discussed the IFNAMSIZ (16) limit for/netdevice name length. Now when we have PF and VF representors/with port names like ""pfXvfY"", it became quite common to hit this limit:/0123456789012345/enp131s0f1npf0vf6/enp131s0f1npf0vf22//Udev cannot rename these interfaces out-of-the-box and user needs to/create custom rules to handle them.//Also, udev has multiple schemes of netdev names. From udev code:/ * Type of names:/ *   b<number>                             - BCMA bus core number/ *   c<bus_id>                             - bus id of a grouped CCW or CCW device,/ *                                           with all leading zeros stripped [s390]/ *   o<index>[n<phys_port_name>|d<dev_port>]/ *                                         - on-board device index number/ *   s<slot>[f<function>][n<phys_port_name>|d<dev_port>]/ *                                         - hotplug slot index number/ *   x<MAC>                                - MAC address/ *   [P<domain>]p<bus>s<slot>[f<function>][n<phys_port_name>|d<dev_port>]/ *                                         - PCI geographical location/ *   [P<domain>]p<bus>s<slot>[f<function>][u<port>][..][c<config>][i<interface>]/ *                                         - USB port number chain/ *   v<slot>                               - VIO slot number (IBM PowerVM)/ *   a<vendor><model>i<instance>           - Platform bus ACPI instance id/ *   i<addr>n<phys_port_name>              - Netdevsim bus address and port name//One device can be often renamed by multiple patterns at the/same time (e.g. pci address/mac).//This patchset introduces alternative names for network interfaces./Main goal is to:/1) Overcome the IFNAMSIZ limitation (altname limitation is 128 bytes)/2) Allow to have multiple names at the same time (multiple udev patterns)/3) Allow to use alternative names as handle for commands//The patchset introduces two new commands to add/delete list of properties./Currently only alternative names are implemented but the ifrastructure/could be easily extended later on. This is very similar to the list of vlan/and tunnels being added/deleted to/from bridge ports.//See following examples.//$ ip link/1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000/    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00/2: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff//-> Add alternative names for dummy0://$ ip link prop add dummy0 altname someothername/$ ip link prop add dummy0 altname someotherveryveryveryverylongname/$ ip link/1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000/    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00/2: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname someothername/    altname someotherveryveryveryverylongname/$ ip link show someotherveryveryveryverylongname/2: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname someothername/    altname someotherveryveryveryverylongname//-> Add bridge brx, add it's alternative name and use alternative names to/   do enslavement.//$ ip link add name brx type bridge/$ ip link prop add brx altname mypersonalsuperspecialbridge/$ ip link set someotherveryveryveryverylongname master mypersonalsuperspecialbridge/$ ip link/1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000/    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00/2: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop master brx state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname someothername/    altname someotherveryveryveryverylongname/3: brx: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname mypersonalsuperspecialbridge//-> Add ipv4 address to the bridge using alternative name://$ ip addr add 192.168.0.1/24 dev mypersonalsuperspecialbridge/$ ip addr show mypersonalsuperspecialbridge/3: brx: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname mypersonalsuperspecialbridge/    inet 192.168.0.1/24 scope global brx/       valid_lft forever preferred_lft forever//-> Delete one of dummy0 alternative names://$ ip link prop del dummy0 altname someotherveryveryveryverylongname/$ ip link/1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000/    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00/2: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop master brx state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname someothername/3: brx: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname mypersonalsuperspecialbridge//-> Add multiple alternative names at once//$ ip link prop add dummy0 altname a altname b altname c altname d/$ ip link/1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000/    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00/2: dummy0: <BROADCAST,NOARP> mtu 1500 qdisc noop master brx state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname someothername/    altname a/    altname b/    altname c/    altname d/3: brx: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000/    link/ether ae:67:a9:67:46:86 brd ff:ff:ff:ff:ff:ff/    altname mypersonalsuperspecialbridge/====================//Signed-off-by: David S. Miller <davem@davemloft.net>",https://github.com/microsoft/WSL2-Linux-Kernel/commit/7a56493f0620cc1b4cffc9bc59289fdefe76b5f3,187922067,microsoft/WSL2-Linux-Kernel,False,False
e1ef035d272ef4dbfdda98e58699698305138856,"Merge tag 'armsoc-defconfig' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc//Pull ARM SoC defconfig updates from Olof Johansson:/ ""Most changes here are to enable new drivers and platforms in the/  various configs that affect them. Most of these have been covered and/  described in the other branches, we mostly keep defconfig separate to/  avoid conflicts between SoC/dt/driver updates that they otherwise/  would be grouped with.//  One thing worth mentioning here is that OMAP changes from using their/  own UART driver, to 8250, for the multi_v7_defconfig shared config on/  32-bit. This means that the console is now named ttyS* instead of/  ttyO*. This change was already done for omap2_defconfig a while back,/  so most users of these configs have either already updated, or can/  easily follow the same patterns as they did at that time. This makes/  platform support slightly easier for distros, since they no longer/  need to keep track of a separate console prefix for these platforms""//* tag 'armsoc-defconfig' of git://git.kernel.org/pub/scm/linux/kernel/git/arm/arm-soc: (31 commits)/  Revert ""arm64: defconfig: Enable FSL_MC_BUS and FSL_MC_DPIO""/  arm64: defconfig: Enable FSL_MC_BUS and FSL_MC_DPIO/  arm64: defconfig: Replace PINCTRL_MT7622 with PINCTRL_MTK_MOORE/  arm64: defconfig: Regenerate for v4.20/  ARM: multi_v7_defconfig: Add TOSHIBA TC358764 bridge driver/  ARM: multi_v7_defconfig: Add MAX8952 regulator driver/  ARM: exynos_defconfig: Add TOSHIBA TC358764 bridge driver/  ARM: exynos_defconfig: Add MAX8952 regulator driver/  ARM: exynos_defconfig: Add MAX8998 RTC and charger drivers/  ARM: imx_v6_v7_defconfig: add imx7ulp support/  ARM: imx_v6_v7_defconfig: Select TOUCHSCREEN_GOODIX/  ARM: multi_v7_defconfig: enable STM32 analog & timer drivers/  arm64: defconfig: Enable GCC and PINCTRL for MSM8998/  arm64: defconfig: Enable core Qualcomm SDM845 options/  ARM: defconfig: Enable the PL111 DRM driver on vexpress/  ARM: defconfig: Update the vexpress defconfig/  arm64: defconfig: Enable some qcom remoteproc configs/  arm64: defconfig: Enable QCS404 configs/  ARM: imx_v6_v7_defconfig: Enable USB_ANNOUNCE_NEW_DEVICES/  ARM: imx_v6_v7_defconfig: Enable BT_BNEP/  ...",https://github.com/microsoft/WSL2-Linux-Kernel/commit/e1ef035d272ef4dbfdda98e58699698305138856,187922067,microsoft/WSL2-Linux-Kernel,False,False
1e2604dcccba77ad12275eb9c7aaf9dc89fb35c1,"[CodeGenPrepare] Reapply r224351 with a fix for the assertion failure:/The type promotion helper does not support vector type, so when make/such it does not kick in in such cases.//Original commit message:/[CodeGenPrepare] Move sign/zero extensions near loads using type promotion.//This patch extends the optimization in CodeGenPrepare that moves a sign/zero/extension near a load when the target can combine them. The optimization may/promote any operations between the extension and the load to make that possible.//Although this optimization may be beneficial for all targets, in particular/AArch64, this is enabled for X86 only as I have not benchmarked it for other/targets yet.///** Context **//Most targets feature extended loads, i.e., loads that perform a zero or sign/extension for free. In that context it is interesting to expose such pattern in/CodeGenPrepare so that the instruction selection pass can form such loads./Sometimes, this pattern is blocked because of instructions between the load and/the extension. When those instructions are promotable to the extended type, we/can expose this pattern.///** Motivating Example **//Let us consider an example:/define void @foo(i8* %addr1, i32* %addr2, i8 %a, i32 %b) {/  %ld = load i8* %addr1/  %zextld = zext i8 %ld to i32/  %ld2 = load i32* %addr2/  %add = add nsw i32 %ld2, %zextld/  %sextadd = sext i32 %add to i64/  %zexta = zext i8 %a to i32/  %addza = add nsw i32 %zexta, %zextld/  %sextaddza = sext i32 %addza to i64/  %addb = add nsw i32 %b, %zextld/  %sextaddb = sext i32 %addb to i64/  call void @dummy(i64 %sextadd, i64 %sextaddza, i64 %sextaddb)/  ret void/}//As it is, this IR generates the following assembly on x86_64:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movl  (%rsi), %es      # plain load/  addl  %eax, %esi       # 32-bit add/  movslq  %esi, %rdi     # sign extend the result of add/  movzbl  %dl, %edx      # zero extend the first argument/  addl  %eax, %edx       # 32-bit add/  movslq  %edx, %rsi     # sign extend the result of add/  addl  %eax, %ecx       # 32-bit add/  movslq  %ecx, %rdx     # sign extend the result of add/[...]/The throughput of this sequence is 7.45 cycles on Ivy Bridge according to IACA.//Now, by promoting the additions to form more extended loads we would generate:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movslq  (%rsi), %rdi   # sign-extended load/  addq  %rax, %rdi       # 64-bit add/  movzbl  %dl, %esi      # zero extend the first argument/  addq  %rax, %rsi       # 64-bit add/  movslq  %ecx, %rdx     # sign extend the second argument/  addq  %rax, %rdx       # 64-bit add/[...]/The throughput of this sequence is 6.15 cycles on Ivy Bridge according to IACA.//This kind of sequences happen a lot on code using 32-bit indexes on 64-bit/architectures.//Note: The throughput numbers are similar on Sandy Bridge and Haswell.///** Proposed Solution **//To avoid the penalty of all these sign/zero extensions, we merge them in the/loads at the beginning of the chain of computation by promoting all the chain of/computation on the extended type. The promotion is done if and only if we do not/introduce new extensions, i.e., if we do not degrade the code quality./To achieve this, we extend the existing “move ext to load” optimization with the/promotion mechanism introduced to match larger patterns for addressing mode/(r200947)./The idea of this extension is to perform the following transformation:/ext(promotableInst1(...(promotableInstN(load))))/=>/promotedInst1(...(promotedInstN(ext(load))))//The promotion mechanism in that optimization is enabled by a new TargetLowering/switch, which is off by default. In other words, by default, the optimization/performs the “move ext to load” optimization as it was before this patch.///** Performance **//Configuration: x86_64: Ivy Bridge fixed at 2900MHz running OS X 10.10./Tested Optimization Levels: O3/Os/Tests: llvm-testsuite + externals./Results:/- No regression beside noise./- Improvements:/CINT2006/473.astar:  ~2%/Benchmarks/PAQ8p: ~2%/Misc/perlin: ~3%//The results are consistent for both O3 and Os.//<rdar://problem/18310086>///git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@224402 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/llvm/commit/1e2604dcccba77ad12275eb9c7aaf9dc89fb35c1,29704274,microsoft/llvm,False,False
1e2604dcccba77ad12275eb9c7aaf9dc89fb35c1,"[CodeGenPrepare] Reapply r224351 with a fix for the assertion failure:/The type promotion helper does not support vector type, so when make/such it does not kick in in such cases.//Original commit message:/[CodeGenPrepare] Move sign/zero extensions near loads using type promotion.//This patch extends the optimization in CodeGenPrepare that moves a sign/zero/extension near a load when the target can combine them. The optimization may/promote any operations between the extension and the load to make that possible.//Although this optimization may be beneficial for all targets, in particular/AArch64, this is enabled for X86 only as I have not benchmarked it for other/targets yet.///** Context **//Most targets feature extended loads, i.e., loads that perform a zero or sign/extension for free. In that context it is interesting to expose such pattern in/CodeGenPrepare so that the instruction selection pass can form such loads./Sometimes, this pattern is blocked because of instructions between the load and/the extension. When those instructions are promotable to the extended type, we/can expose this pattern.///** Motivating Example **//Let us consider an example:/define void @foo(i8* %addr1, i32* %addr2, i8 %a, i32 %b) {/  %ld = load i8* %addr1/  %zextld = zext i8 %ld to i32/  %ld2 = load i32* %addr2/  %add = add nsw i32 %ld2, %zextld/  %sextadd = sext i32 %add to i64/  %zexta = zext i8 %a to i32/  %addza = add nsw i32 %zexta, %zextld/  %sextaddza = sext i32 %addza to i64/  %addb = add nsw i32 %b, %zextld/  %sextaddb = sext i32 %addb to i64/  call void @dummy(i64 %sextadd, i64 %sextaddza, i64 %sextaddb)/  ret void/}//As it is, this IR generates the following assembly on x86_64:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movl  (%rsi), %es      # plain load/  addl  %eax, %esi       # 32-bit add/  movslq  %esi, %rdi     # sign extend the result of add/  movzbl  %dl, %edx      # zero extend the first argument/  addl  %eax, %edx       # 32-bit add/  movslq  %edx, %rsi     # sign extend the result of add/  addl  %eax, %ecx       # 32-bit add/  movslq  %ecx, %rdx     # sign extend the result of add/[...]/The throughput of this sequence is 7.45 cycles on Ivy Bridge according to IACA.//Now, by promoting the additions to form more extended loads we would generate:/[...]/  movzbl  (%rdi), %eax   # zero-extended load/  movslq  (%rsi), %rdi   # sign-extended load/  addq  %rax, %rdi       # 64-bit add/  movzbl  %dl, %esi      # zero extend the first argument/  addq  %rax, %rsi       # 64-bit add/  movslq  %ecx, %rdx     # sign extend the second argument/  addq  %rax, %rdx       # 64-bit add/[...]/The throughput of this sequence is 6.15 cycles on Ivy Bridge according to IACA.//This kind of sequences happen a lot on code using 32-bit indexes on 64-bit/architectures.//Note: The throughput numbers are similar on Sandy Bridge and Haswell.///** Proposed Solution **//To avoid the penalty of all these sign/zero extensions, we merge them in the/loads at the beginning of the chain of computation by promoting all the chain of/computation on the extended type. The promotion is done if and only if we do not/introduce new extensions, i.e., if we do not degrade the code quality./To achieve this, we extend the existing “move ext to load” optimization with the/promotion mechanism introduced to match larger patterns for addressing mode/(r200947)./The idea of this extension is to perform the following transformation:/ext(promotableInst1(...(promotableInstN(load))))/=>/promotedInst1(...(promotedInstN(ext(load))))//The promotion mechanism in that optimization is enabled by a new TargetLowering/switch, which is off by default. In other words, by default, the optimization/performs the “move ext to load” optimization as it was before this patch.///** Performance **//Configuration: x86_64: Ivy Bridge fixed at 2900MHz running OS X 10.10./Tested Optimization Levels: O3/Os/Tests: llvm-testsuite + externals./Results:/- No regression beside noise./- Improvements:/CINT2006/473.astar:  ~2%/Benchmarks/PAQ8p: ~2%/Misc/perlin: ~3%//The results are consistent for both O3 and Os.//<rdar://problem/18310086>///git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@224402 91177308-0d34-0410-b5e6-96231b3b80d8",https://github.com/microsoft/checkedc-llvm/commit/1e2604dcccba77ad12275eb9c7aaf9dc89fb35c1,60644745,microsoft/checkedc-llvm,False,False
8a890ddfd749a2f46609f8e234f192780bb41356,"Sync ORTModule branch with master and fix tests (#6526)//* Deprecate Python global configuration functions [Part 1] (#5923)////Enable options to be set via execution provider (EP)-specific options and log deprecation warning from current global configuration functions.////* remove dnnl_dll_path from post build copy (#6142)////* Model Fusion For Bart (#6105)////Fusion fix for Bart models////* Unify IExecutionProvider and IExecutionProviderFactory interfaces (#6108)////* Remove Provider_IExecutionProvider and make the internal IExecutionProvider usable by shared providers//* Change Provider_IExecutionProviderFactory to be the core version.////* Enable running the mnist_training sample without cuda (#6085)////Signed-off-by: George Nash <george.nash@intel.com>////* nnapi add min max support (#6117)////* Fix CUDA test hang: (#6138)////- Make condition check in `CUDAAllocatorTest` to ensure CUDA device is present.////* Fix TensorRT kernel conflict issue for subgraphs of control flow operators (#6115)////* add static subgraph kernel index////* change kernel naming to avoid conflicts////* Add gradient registration for Abs. (#6139)////* Partition initial optimizer state for Zero-1 (#6093)////* Initial changes////* Working changes////* Working changes////* Cleanup////* fix windows CI////* Review comments////* review comments////* Fix edge case in BFCArena where allocation failures could lead to an infinite loop. (#6145)////#4656////* Revert ""work around of the build break in mac (#6069)"" (#6150)////This reverts commit 3cae28699bed5de1fcaadb219fa69bae0fc3cee8.////* Fix clean_docker_image_cache.py detection of image pushes. (#6151)////Fix clean_docker_image_cache.py detection of image pushes. They were being ignored because the expected HTTP status code was wrong. For pushes, it's 201 instead of 200.////* MLAS: add NEON version of int8 depthwise convolution (#6152)////* Using a map of of ops to stages as input of partition function. (#5940)////* New partition algorithm running before AD////* Convert cut_group_info into device map. Work in progress -- works for  bert-tiny with pp=2////* Removing code for partition of bwd graphs////* Remove old code////* Adding some verification code////* Handle Shared Initializer////* Renaming rank with stage////* Added first unit test////* new test////* redundant check////* undo change in bert////* Moved cut-based partition to testing utils file////Co-authored-by: xzhu1900//Co-authored-by: wschin////* New conversion function and tests////* minor////* remove test that is not needed2////* improve GetDeviceAssignment and PR comments////* minor changes////* PR comments////* improving documentation and variable naming////* add documentation////* Variable naming and docs////* more doc improvements////* more doc improvements////* missing static cast////* Fix test file for windows////* Fix test file for windows////* Fix test file for windows////* stage id is not the same as rank id////* PR comments////* PR comments////* More comments////* More comments////* Minor fix to satisfy c++14 (#6162)////* Deprecating Horovod and refactored Adasum computations (#5468)////deprecated horovod submodule//refactored adasum logic to be ort-native//added tests for native kernel and e2e tests////* Update TensorRT-ExecutionProvider.md (#6161)////* Bugfix for topk cuda kernel (#6164)////* fix the issue that std::numeric_limits cannot handle half type////* adding a test////Co-authored-by: Du Li <duli@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>////* Revert ""Fuse MatMulIntegerToFloat only when scales are scalar (#6008)"" (#6169)////This reverts commit f2dcba7afe0d42ebdaaef0c6cdf913a1156c9e98.////* Remove ignored build warnings for pybind on Mac (#6165)////* save_checkpoint, load_checkpoint and aggregate_checkpoints (#6136)////* save_checkpoint and load_checkpoint implementations////* checkpoint aggregation logic////* unit tests for save_checkpoint, load_checkpoint and aggregate_checkpoints////* Don't try to bind unused inputs in the Training frontend (#6166)////* Update documentation for contributing a PR and add deprecation notices for PyOp and ORT server. (#6172)////* aggregate model states only for the case when mixed precision was true (#6176)////* [NNAPI EP] Enable per-channel quantization for QlinearConv  (#6155)////* Enable qlinearconv per-channel quantization////* Fix the android CI test failure////* Add Android Version Check for Per-Channel Quant////* Address PR comments////* Fix some minor issues////* Add verification of per-channel zero points////* Make the error tolerance configurable////* Fix typo in BERT pretraining script (#6175)////A misplaced `}` meant that the `'enable_adasum'` option was interpreted incorrectly, causing the test to fail.////* Update get_docker_image.py to enable use without image cache container registry. (#6177)////Update get_docker_image.py to enable use without image cache container registry.////* Helper for compiling EP to generate deterministic unique ids for use in MetaDef names (#6156)////* Create a helper for generating unique ids that can be used by an EP that creates compiled nodes and needs ids to be deterministic for a model when used in multiple sessions.////Added to IExecutionProvider as this can potentially be used by all compiling EPs and is more robust than a simplistic counter (although EP implementer is free to choose either approach).////* Restructure the helper so it can be called across the EP bridge.//Add ability to call id generation helper from EP bridge//  - convert DNNL EP to use helper to validate//Address issue where a new Model may be loaded into the same address as a previous one.//  - hash the bytes in the Graph instance (1728 bytes currently) to use as the key to the full hash for the model//Add lock around id generation to ensure no issues if multiple sessions partitions graphs at exactly the same time.//  - Extremely unlikely but would be hard to debug and the locking cost is not an issue as it's only incurred during graph partitioning and not execution.////* Backend APIs for checkpointing (#5803)////* Add backend API GetOptimizerState and GetModelState////* add GetPartitionInfoMap////* Android coverage dashboard (#6163)////* Write the report to a file.////* Post code coverage to the Dashboard database.////* Add usage details of unified MCR container image (#6182)////Going forward, a single unifed docker image will be published in//MCR. The hardware accelerator target choice will have to be made//in the application using OpenVINO EP's runtime config options.////* improve perf for softmax (#6128)////* improve perf for both gathergrad and softmax////* revert the change in gathergrad and will be done in another PR.////* address comments from code review.////* Tune fast Gelu to use exp(x) instead of tanh(x) on Rocm platform (#6174)////* tune fast gelu to use exp(x) instead of tanh(x) on rocm////* update to use expression 2/(1+exp(-2x))-1 for stability////* Add Status.csv to EP Perf Tool (#6167)////* merge master, keep postprocess status commit////* download float16.py everytime////* removing hardcoded values////* Lochi/quantization tool for trt (#6103)////* Initial implementation of generating calibration dynamic range table////* Initialize validation support for Quantization////* Initialize validation support for Quantization (cont.)////* Improve validation support for Quantization////* Improve validation support for Quantization////* Rewrite/Refine for calibration and validation////* Rewrite/Refine for calibration and validation (cont.)////* Refine code////* Refine code////* Add data reader for BERT////* Add flatbuffers to serialize calibration table////* Refine code and add BERT evaluation////* Refine the code////* minor modification////* Add preprocess/postprocess of vision team yolov3 and refine the code////* Update annotation////* Make bbox cooridates more accurate////* Fix bug////* Add support of batch processing////* Batch processing for model zoo yolov3////* Add batch inference for evaluation////* Refine the code////* Add README////* Add comments////* Refine the code for PR////* Remove batch support checking in data_reader and refine the code////* Refine the code for PR////* Refine the code for PR review////Co-authored-by: Olivia Jain <oljain@microsoft.com>////* Implement ScatterND for CUDA EP (#6184)////* Condition fix in Resize operator (#6193)////* Clean up checkpoint tests to use the new checkpoint functions (#6188)////* add deprecation warning for old checkpoint functions////* update all the distributed checkpoint tests to use new checkpoint functions////* Implement comparing outputs that are sequence of maps of strings to floats (#6180)////* Implement conversion from ortvalue to Itensor for string tensors and comparing sequence of maps of strings to floats////* PR comments////* Dockerfile to build onnxruntime with ROCm 4.0////* Add ability to skip GPU tests based on GPU adapter name (#6198)////* Implement conversion from ortvalue to Itensor for string tensors and comparing sequence of maps of strings to floats////* PR comments////* Add ability to skip gpu tests according to adapter description////* spacing////* spacing////* spacing////* Openvino ep 2021.2 (#6196)////* Enabling fasterrcnn variant and vehicle detector////* changes for 2021_2 branch////* yolov3_pytorch commit////* fixed braces in basic_backend.cc////* ci information added////* faster rcnn variant and vehicle detector changes were made in 2021.1 and not in 2021.2////* some changes to support unit tests////* disable some tests which are failing////* fix myriad tests for vehicle detector////* Did some cleanup//*cleaned up comments//*Disabled Add_Broadcast_0x1 and Add_Broadcast_1x0//tests on MYRIAD_FP16 backend due to a bug//*cleaned up capability_2021_2.cc file//*Removed extra conditions which were added//for some validation in backend_utils////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* yolov3 pytorch workaround to ensure that the output names are matched////* gemmoptest fixed on myriad////* Fixed MYRIADX CPP Test Failures////*Expand,GatherND,Range,Round op's//are only supported in model////*where op with float input data//types are not supported and fixed////*Scatter and ScatterElements op's with//negative axis are fixed////*Reshape op with 0 dim value are not//supported and fixed////*Disabled InstanceNorm_2 test on MYRIADX////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* make changes to yolov3 pytorch////* Fixed python unit tests//*Fixed failing python tests on vpu,//GPU and CPU////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* Fixes POW op failures on GPU_FP16////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* Clean up capability_2021_2.cc////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* Updated docx for MultiThreading option//*Added extra info on setting the num_of_threads//option using the API and it's actual usage////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* fixed slice and removed extra prints////* Disabled failing python tests////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* Minor changes added in capabilty_2021_2////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* made changes to slice to avoid failures////* Disabling FP16 support for GPU_FP32//->Inferencing an FP16 model on GPU_FP32//leads to accuracy mismatches. so, we would//rather use GPU_FP16 to infer an FP16 model//on GPU Device////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* Updated docx for Inferencing a FP16 Model////Signed-off-by: MaajidKhan <n.maajidkhan@gmail.com>////* fix for mask rcnn////* Script for installing openvino from source////* Updated with openvino 2021.2 online installation////* code comment fixes//fixed accuracy mismatch for div////* Update OpenvinoEP-ExecutionProvider.md////updated for 2021.2 branch////* Update README.md////updated dockerfile documentation////* Update BUILD.md////build.md update documentation////* permissiong change of install_openvino.sh////* made changes to align with microsoft onnxruntime changes////* Updated with ov 2021.2.200////Co-authored-by: suryasidd <surya.siddharth.pemmaraju@intel.com>//Co-authored-by: sfatimar <sahar.fatima@intel/com>//Co-authored-by: MaajidKhan <n.maajidkhan@gmail.com>//Co-authored-by: mohdansx <mohdx.ansari@intel.com>////* Fix a memory leak in test_inference.cc (#6201)////* Fix a memory leak in test_inference.cc////* Use TArray in AMD element-wise kernels, rather than manually copying memory to device.////* Remove most ROCm-specific element-wise code and reuse CUDA element-wise code.////* Minor change to improve performance for operator Pad. (#5537)////* small improvment for pad////* Support double for operators Log, Reciprocal, Sum (CPU) (#6032)////* Support double for operators Log, Reciprocal, Sum//* remove tesdt erf_double////* Support double for operators Where, LpNormalisation (#6034)////* Support double for operators Relu, Tanh, Sigmoid (#6221)////* Fix ImportError in build.py (#6231)////There is a possible ImportError where build.py can import the wrong 'util' package if there are others present in `sys.path` already////* Removed executor todo that looks dead. (#6234)////* Remove MKLML/openblas/jemalloc build config (#6212)////* Remove python 3.5////* Update the readme file////* Upgrade build.py to assert for python 3.6+////Upgrade build.py to assert for python 3.6+//as python 3.5 cannot build anymore todays master.////* Support MLFloat16 type in Pow opset-12 CUDA kernel (#6233)////* MLAS: handle MlasGemm(M/N/K==0) cases (#6238)////* Support double for operator TopK + fix one bug in TopK implementation for GPU for double (#6220)////* Support double for operator TopK//* add static classes for topk/double//* fix cast issue in topk////* Support double for operator Gemm + fix bug in gemm implementation for cuda, rocm when sizeof(type) != sizeof(float) (#6223)////* Support double for operator Gemm//* fix type size while copying data in gemm operator for GPU//* fix type in gemm implementation for rocm////* Support double for operator ReduceMean, ReduceLogSumExp (#6217)////* Support double for operators ReduceMean, ReduceLogSumExp////* Support double for operator ArgMin (#6222)////* Support double for operator ArgMin//* add test specifically for double//* add new test on pai-excluded-tests.txt////* Update BUILD.md////* Update manylinux docker image to the latest (#6242)////* Fix allocator issue for TensorRT IOBinding (#6240)////* Fix issue: https://github.com/microsoft/onnxruntime/issues/6094////Root cause: we didn't expose the OrtMemoryInfo for TRT, so it will cause issue if user want use IObinding for Tensorrt.////Short term fix, add the OrtMemoryInfo for TRT. Long term should unify the allocator for CUDA and TRT////* Tune BiasGeluGradDx kernel in approximation mode to avoid tanh(...) on Rocm (#6239)////* bias gelu grad use exp(...) instead////* update cuda to rocm////* missing semicolon////* comment////* remove dockerfile////* missing factor of two////* Refactor EP Perf Tool  (#6202)////* merge master, keep postprocess status commit////* download float16.py everytime////* using variables to reference eps////* adding ACL EP to ep perf tool////* accuracy with absolute tolerance configurable////* add acl to dict + remove commented line////* Documentation for distributed CI tests pipeline (#6140)////* Remove a debug log in provider_test_utils.cc (#6200)////* Add the Concat Slice Elimination transform, fix constant_folding transform (#5457)////* Add concat slice transform + test////* Cosmetic improvements in concat slice transform////* Remove unrelated file, fix comment, fix constant folding bug////* Add test onnx graph////* fix windows build////* Review comments////* review comment////Co-authored-by: Aishwarya <aibhanda@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>////* Add MakeStringLite which uses current locale, update some MakeString call sites to use it instead. (#6252)////* Add MakeStringLite which uses current locale, update macros to use that to generate messages.////* Convert calls to MakeStringLite().////* Liqun/speech model loop to scan (#6070)////Provide a tool to convert Loop to Scan for Nuphar performance//Fix Nuphar CI pipeline failures.////Co-authored-by: liqun <liqun@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>////* model parallel refinement (#6244)////* Megatron Transformation as a seperate step////* remove useless header////* clang formating////* Re-Structure megatron transformer for subsquent changes////* fix  comments////* Allow querying a GraphProto's doc_string as part of ModelMetadata (#6248)////* Fix Linux/Mac error message on input type mismatch (#6256)////* add bfloat16 to gathergrad type constrains (#6267)////Co-authored-by: Cheng Tang <chenta@microsoft.com>////* Fix VS 2017 build break (#6276)////* Deprecate Python global configuration functions [Part 2] (#6171)////Update Python API to allow more flexibility for setting providers and provider options.////The providers argument (InferenceSession/TrainingSession constructors, InferenceSession.set_providers()) now also accepts a tuple of (name, options dict).//Fix get_available_providers() API (and the corresponding function in the C API) to return the providers in default priority order. Now it can be used as a starting point for the providers argument and maintain the default priority order.//Convert some usages of the deprecated global configuration functions to use EP-specific options instead.////Update some EP-specific option parsing to fail on unknown options.////Other clean up.////* Add script to preprocess python documentation before publishing (#6129)////* add script to preprocessing python documentation before publishing////* rename past to past_key_values for GPT-2 (#6269)////rename past to past_key_values for transformers 4.*////* Rename MakeString and ParseString functions. (#6272)////Rename MakeString to MakeStringWithClassicLocale, MakeStringLite to MakeString, *ParseString to *ParseStringWithClassicLocale.//Add missing pass-through versions of MakeStringWithClassicLocale for string types.////* Increase timeout for Linux GPU CUDA11 build. (#6280)////* Add helper to compare model with different precision (#6270)////* add parity_check_helper.py////* add real example////* remove lines////* Fix Min/Max CPU kernels for float16 type (#6205)////* fix data_ptr assertion error for past_sequence_length=0 in GPT-2 (#6284)//// fix io binding crash for past_sequence_length=0////* A list of changes in transformers tool (#6224)////* longformer fp16 e2e////* add fp16/fp32 parity check helper file////* excludes nodes with subgraph in profiling////* use onnxconverter_common to do fp32->fp16////* add version check for onnxconverter_common////* remove helper file////* add pkg installation on notebooks and script////* Workaround for static_cast<double>(half)////* Add workaround to remove ROCm-specific binary-elementwise files.////* Update nuget build (#6297)////1. Update the ProtoSrc path. The old one is not used anymore.//2. Regenerate OnnxMl.cs//3. Delete some unused code in tools/ci_build/build.py//4. Avoid set intra_op_param.thread_pool_size in ModelTests in OpenMP build.//5. Fix a typo in the C API pipeline.////* Enable ONNX backend test of SequenceProto input/output  (#6043)////* assert sequence tensor and remove skips////* update testdata json////* use ONNX 1.8 in cgmanifest.json////* use previous commit to workaround////* update ONNX commit ID in docker////* skip test_maxpool_2d_dilations test for now////* update function name////* add --sequence_lengths option (#6285)////* more dtype for Equal CUDA kernel (#6288)////Co-authored-by: Vincent Wang <weicwang@microsoft.com>////* Force reinstall onnx python package on Windows (#6309)////* update transformers required package versions (#6315)////* Remove abs in LpPool (#6303)////* Support 1D input for Conv + Mul/Add fusion optimizer with test (#6295)////* Support 1D input (N C H) for Conv + Mul/Add fusion optimizer with test cases and test models.////* Add longformer to  python package (#6314)////* add longformer to python package//* move test related script and data to a new folder////* Avoid false sharing on thread pool data structures (#6298)////Description: This change adds alignment and padding to avoid false sharing on fields in the thread pool. It also adds a new microbenchmark to profile thread-pool performance over short loops.////Motivation and Context//MobileNet on a 2*12-core system showed a performance gap between the ORT thread pool and OpenMP. One cause appeared to be false sharing on fields in the thread pool: ThreadPoolParallelSection::tasks_finished (which the main thread spins on waiting for workers to complete a loop), and the RunQueue::front_ and back_ fields (used respectively by the worker thread and the main thread).////The additional micro-benchmark BM_ThreadPoolSimpleParallelFor tests performance of loops of different sizes at different thread counts. The results below are on a machine with 2*14-core processors (E5-2690 v4) running with 1, 14, 15, and 28 threads. For each test, the microbenchmark has N threads run a loop with N iterations; hence a perfect result is for the time taken to be constant as additional threads are added (although we will also see power management effects helping at very low thread counts). The loop durations (100000, 10000, 1000) correspond roughly to 200us, 20us, and 2us on this machine.////Before change://BM_ThreadPoolSimpleParallelFor/1/1/100000/real_time 17153 us 17154 us 32//BM_ThreadPoolSimpleParallelFor/14/14/100000/real_time 22553 us 22553 us 30//BM_ThreadPoolSimpleParallelFor/15/15/100000/real_time 21521 us 21521 us 29//BM_ThreadPoolSimpleParallelFor/28/28/100000/real_time 24111 us 24111 us 24//BM_ThreadPoolSimpleParallelFor/1/1/10000/real_time 1719 us 1719 us 407//BM_ThreadPoolSimpleParallelFor/14/14/10000/real_time 3409 us 3409 us 200//BM_ThreadPoolSimpleParallelFor/15/15/10000/real_time 3541 us 3541 us 201//BM_ThreadPoolSimpleParallelFor/28/28/10000/real_time 4576 us 4576 us 151//BM_ThreadPoolSimpleParallelFor/1/1/1000/real_time 174 us 174 us 4017//BM_ThreadPoolSimpleParallelFor/14/14/1000/real_time 1586 us 1586 us 402//BM_ThreadPoolSimpleParallelFor/15/15/1000/real_time 1586 us 1586 us 397//BM_ThreadPoolSimpleParallelFor/28/28/1000/real_time 2864 us 2864 us 232////After change://BM_ThreadPoolSimpleParallelFor/1/1/100000/real_time 17160 us 17160 us 33//BM_ThreadPoolSimpleParallelFor/14/14/100000/real_time 20989 us 20989 us 31//BM_ThreadPoolSimpleParallelFor/15/15/100000/real_time 22286 us 22286 us 31//BM_ThreadPoolSimpleParallelFor/28/28/100000/real_time 24631 us 24631 us 25//BM_ThreadPoolSimpleParallelFor/1/1/10000/real_time 1718 us 1718 us 407//BM_ThreadPoolSimpleParallelFor/14/14/10000/real_time 2868 us 2868 us 242//BM_ThreadPoolSimpleParallelFor/15/15/10000/real_time 2907 us 2907 us 240//BM_ThreadPoolSimpleParallelFor/28/28/10000/real_time 3872 us 3872 us 186//BM_ThreadPoolSimpleParallelFor/1/1/1000/real_time 175 us 175 us 3938//BM_ThreadPoolSimpleParallelFor/14/14/1000/real_time 933 us 933 us 659//BM_ThreadPoolSimpleParallelFor/15/15/1000/real_time 912 us 912 us 591//BM_ThreadPoolSimpleParallelFor/28/28/1000/real_time 1976 us 1976 us 317////* fix opset imports for function body  (#6287)////* fix function opsets////* add tests and update onnx////* changes per review comments////* add comments////* plus updates////* build fix////* Remove false positive prefast warning from threadpool (#6324)////* Java: add Semmle to Java publishing pipelines (#6326)////Add Semmle to Java API pipeline//  Add security results publishing and add Java GPU.////* Quantization support for split operator with its NHWC support (#6107)////* Make split working for quantization.////* NHWC transformer support for split operator////* Refactor some according to Feedback. Will add test cases soon.////* Fix build error on windows.////* Add test case for split op on uint8_t support////* Add nhwc_transformer_test for split uint8_t support////* Some change according to PR feedbacks.////* Liqun/enable pipeline parallel test (#6331)////enable pipeline parallel test//Co-authored-by: liqun <liqun@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>////* Use onnxruntime_USE_FULL_PROTOBUF=OFF for the cuda execution provider (#6340)////This removes a special case of the cuda EP.////* MLAS: add fallback implementation for quantized GEMM (#6335)////Add a non-vectorized version of the kernel used for the quantized version of MlasGemm.////* Delete float16.py (#6336)////No longer needed. Also doesn't pass policheck.////* Enable add + softmax fusion for Rocm platform (#6259)////* add bias softmax; tests appear to pass////* check fusion occurs for rocm as well////* check for rocm provider compatible as well////* build for cpu scenario as well////* try again; broader cope////* proper scope on kGpuExecutionProvider////* been editing wrong file////* remove commented #include lines////* try again due to mac os ci error////* try again////* test fusion both cuda and rocm to avoid mac ci error////* add external data support to tensor proto utils (#6257)////* update unpack tensor utilities to support loading external data////* more updates////* fix test////* fix nuphar build////* minor build fix////* add tests////* fix Android CI////* fix warning////* fix DML build failure and some warnings////* more updates////* more updates////* plus few updates////* plus some refactoring////* changes per review////* plus some change////* remove temp code////* plus updates to safeint usage////* build fix////* fix for safeint////* changed wording. (#6337)////* Remove OpSchema dummy definition. Only needed for Function now, and we can just exclude the method in Function (#6321)////* remove gemmlowp submodule (#6341)////* [NNAPI] Add pow support (#6310)////* Add support for running Android emulator from build.py on Windows. (#6317)////* fix the pipeline failure (#6346)////* Train BERT Using BFloat16 on A100 (#6090)////* traing bert using bf16////* Adam support bf16////* bugfix////* add fusedmatmul support////* fix after merge from master.////* bugfix////* bugfix after merge from master////* fast reduction for bf16.////* resolve comments////* fix win build////* bugfix////* change header file.////Co-authored-by: Vincent Wang <weicwang@microsoft.com>////* Fix DerefNullPtr issues raised by SDLNativeRules. (#6348)////* update quantize to support basic optimization and e2e example for image classification (#6313)////update the resnet50-v1 to standard one from onnx zoo.//add an example for mobilenet//run basic optimization before quantization//fix a bug in Clip////* Enable graph save for orttrainer (#6333)////* Enable graph save for orttrainer////* Fix CI////* Update orttraining/orttraining/python/training/orttrainer_options.py////* Update orttraining/orttraining/python/training/orttrainer_options.py////* Update orttraining/orttraining/python/training/orttrainer_options.py////* Update orttraining/orttraining/python/training/orttrainer_options.py////* Update orttraining/orttraining/python/training/orttrainer_options.py////Co-authored-by: Thiago Crepaldi <thiago.crepaldi@microsoft.com>////* Add PREfast to python packaging pipeline (#6343)////* Add PREfast to python packaging pipeline////* fix longformer benchmark io_binding output_buffers (#6345)////* fix longformer benchmark io_binding output_buffers////* format////* import benchmark_helper from parent directory.////* Use readelf for minimal build binary size checks. (#6338)////* Use readelf for minimal build binary size checks.//The on-disk size grows in 4KB chunks which makes it hard to see how much growth an individual checkin causes.//Only downside is that the sum of the sections is larger than the on-disk size (assumably things get packed smaller on disk and some of the section alignment constraints can be ignored)////* Remove unused function////* Java: Set C language warnings to W4 and adjust JNI code (#6347)////Set /W3 for C language and fix up JNI warnings.////* Pipeline Parallel Experimental Python API (#5815)////* Add create session to WinML telemetry to track WinML Usage (#6356)////* Fix one more SDL warning (#6359)////* fix -Wdangling-gsl (#6357)////* Add python example of TensorRT INT8 inference on ResNet model (#6255)////* add trt int8 example on resnet model////* Update e2e_tensorrt_resnet_example.py////* remove keras dependency and update class names////* move ImageNetDataReader and ImageClassificationEvaluator to tensorrt resnet example////* simplify e2e_tensorrt_resnet_example.py////* Update preprocessing.py////* merge tensorrt_calibrate////* Update calibrate.py////* Update calibrate.py////* generalize calibrate////* Update calibrate.py////* fix issues////* fix formating////* remove augment_all////* This added telemetry isn't needed (#6363)////* Wezuo/memory analysis (#5658)////* merged alloc_plan////* pass compilation////* Start running, incorrect allocation memory info////* add in comments////* fix a bug of recording pattern too early.////* debugging lifetime////* fix lifetime////* passed mnist////* in process of visualization////* Add code to generate chrome trace for allocations.////* in process of collecting fragmentation////* before rebuild////* passed mnist////* passed bert tiny////* fix the inplace reuse////* fix the exception of weight in pinned memory////* add guards to ensure the tensor is in AllocPlan////* add customized profiling////* debugging////* debugging////* fix the reuse of differnt location type////* add rank////* add the rank////* add fragmentation////* add time_step_trace////* Add summary for each execution step (total bytes, used/free bytes).////* add top k////* change type of top k parameter////* remove prints////* change heap to set{////* add the name pattern////* add the useage for pattern////* add partition////* change to static class////* add custom group////* remove const////* update memory_info////* in process of adding it as runtime config////* change the memory profiling to be an argument////* add some comments////* add checks to recored meomry_info in traaining session////* set the ""local rank setting"" to correct argument.////* addressing comments////* format adjustment////* formatting////* remove alloc_interval////* update memory_info.cc to skip session when there is no tensor for a particular memory type////* fix memory_info multiple iteration seg-fault////* consolidate mainz changes////* fixed some minor errors////* guard by ORT_MINIMAL_BUILD////* add ORT_MEMORY_PROFILE flag////* added compiler flag to turn on/off memory profiling related code////* clean up the code regarding comments////* add comments////* revoke the onnx version////* clean up the code to match master////* clean up the code to match master////* clean up the code to match master////Co-authored-by: Jesse Benson <benson.jesse@gmail.com>//Co-authored-by: Wei Zuo <wezuo@OrtTrainingDev3.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: wezuo <wezuo@az-eus-v100-32gb-5-worker-mgtbby.eastus.cloudapp.azure.com>//Co-authored-by: wezuo <wezuo@az-eus-v100-32gb-5-worker-yclzsf.eastus.cloudapp.azure.com>////* Support MLFloat16 in CumSum Cuda op for Opset 14 (#6355)////* Add CumSum-14 for Cuda////* fix convert_common version retrival (#6382)////* Refine auto_pad based pad computation in ConvTranspose (#6305)////* Fix SDL warning (#6390)////* Add max_norm for gradient clipping. (#6289)////* add max_norm as user option for gradient clipping////* add adam and lamb test cases for clip norm////* add frontend tests////* Add the custom op project information (#6334)////* Dont use default string marshalling in C# (#6219)////* Fix Windows x86 compiler warnings in the optimizers project  (#6377)////* [Perf] Optimize Tile CPU and CUDA kernels for a corner case (#6376)////* Unblock Android CI code coverage failure (#6393)////* fix build on cuda11 (#6394)////Co-authored-by: Vincent Wang <weicwang@microsoft.com>////* Load the model path correctly (#6369)////* Fix some compile warnings (#6316)////* OpenVino docker file changes to bypass privileged mode////Description: Builds and installs libusb without UDEV support, which is used for communicating with the VPU device.////Motivation and Context////This enables the resulting docker container to be run without '--privileged' and '--network host' options which may not be suitable in deployment environments.////* Megatron checkpointing (#6293)////* Add bart fairseq run script////* Add frontend change to enable megatron////* Initial changes for checkpointing////* Megatron optim state loading, checkpoint aggregation, frontend distributed tests for H, D+H////* Add load_checkpoint changes////* Fix CI////* Cleanup////* Fix CI////* review comments////* review comments////* review comments:////* Fix generate_submodule_cgmanifest.py Windows issues. (#6404)////* Continue memory planning when unknown shape tensor is encountered. (#6413)////* Reintroduce experimental api changes and fix remote build break (#6385)////Co-authored-by: Ori Levari <orlevari@microsoft.com>////* Add support for custom ops to minimal build. (#6228)////* Add support for custom ops to minimal build.//Cost is only ~8KB so including in base minimal build.////* enable pipeline to run quantization tests (#6416)////* enable pipeline to run quantization tests//setup test pipeline for quantization////* Minor cmake change (#6431)////* Liqun/liqun/enable pipeline parallel test2 (#6399)////* enable data and pipeline parallism test////Co-authored-by: liqun <liqun@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>////* Farewell TrainableDropout (#5793)////* Deprecate TrainableDropout kernel.////* Update bert_toy_postprocessed.onnx to opset 12.////* Add more dropout tests.////* Fix BiasDropout kernel.////Co-authored-by: Ubuntu <OrtTrainingDev3@OrtTrainingDev3.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: Sherlock Huang <bahuang@OrtTrainingDev3.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: Sergii Dymchenko <sedymche@microsoft.com>////* fix null dereference warning (#6437)////* Expose graph ModelPath to TensorRT shared library (#6353)////* Update graph_viewer.cc////* Update tensorrt_execution_provider.cc////* Update graph_viewer.h////* Update tensorrt_execution_provider.cc////* Update tensorrt_execution_provider.cc////* Update provider_api.h////* Update provider_bridge_ort.cc////* Update provider_interfaces.h////* Update provider_interfaces.h////* expose GraphViewer ModelPath API to TRT shared lib////* add modelpath to compile////* update////* add model_path to onnx tensorrt parser////* use GenerateMetaDefId to generate unique TRT kernel name////* use GenerateMetaDefId to generate unique TRT engine name////* fix issue////* Update tensorrt_execution_provider.cc////* remove GetVecHash////* Update tensorrt_execution_provider.h////* convert wchar_t to char for tensorrt parser////* update tensorrt parser to include latest changes////* fix issues////* Update tensorrt_execution_provider.cc////* merge trt parser latest change////* add PROVIDER_DISALLOW_ALL(Path)////* add tool for generating test data for longformer (#6415)////* only build experimental api in redist (#6465)////Co-authored-by: Sheil Kumar <sheilk@microsoft.com>////* Add an option to save the training graph after optimization (#6410)////* expose optimized_model_filepath in SessionOptions as `debug.graph_save_paths.model_with_training_graph_after_optimization_path` in `ORTTrainerOptions`////* Share allocator between CUDA EP & TRT EP. (#6332)////* Share allocator between CUDA EP & TRT EP.//limitation://1. Does not cover the per-thread allocator created by CUDA EP, still need to figure out the way to remove it//2. Need to have more identifiers to make it able to share CPU allocator across all EPs////* fix max norm clipping test in python packaging pipeline test (#6468)////* fix python packaging pipeline////* make clip norm test compatabile with both V100 and M60 GPUs////* Initial version of CoreML EP (#6392)////* Bug 31463811: Servicing: Redist (Nuget) conflicts with Microsoft.AI.MachineLearning starting 21H1+ (#6460)////* update load library code to have the fullly qualified path////* make it work for syswow32////* git Revert ""make it work for syswow32""////This reverts commit b9f594341b7cf07241b18d0c376af905edcabae3.////Co-authored-by: Sheil Kumar <sheilk@microsoft.com>////* dequantize 1st input of lstm back if it is quantized (#6444)////* [java] Adds support for OrtEnvironment thread pools (#6406)////* Updates for Gradle 7.////* Adding support for OrtThreadingOptions into the Java API.////* Fixing a typo in the JNI code.////* Adding a test for the environment's thread pool.////* Fix cuda test, add comment to failure.////* Updating build.gradle////* fix SDL native rule warning #6246 (#6461)////* fix SDL rule (#6464)////* use tickcount64 (#6447)////Co-authored-by: Ori Levari <orlevari@microsoft.com>////* Update pypi package metadata (#6354)////* Update setup file data////* add missing comma////* remove python 3.5////* fix typo bracket////* Delete nuget extra configs (#6477)////* Op kernel type reduction infrastructure. (#6466)////Add infrastructure to support type reduction in Op kernel implementations.//Update Cast and IsInf CPU kernels to use it.////* Fixing a leak in OnnxSequences with String keys or values. (#6473)////* Increase the distributes tests pipeline timeout to 120 minutes (#6479)////* [CoreML EP] Add CI for CoreML EP (macOS) and add coreml_flags for EP options (#6481)////* Add macos coreml CI and coreml_flags////* Move save debuggubg model to use environment var////* Move pipeline off from macos CI template////* Fix an issue building using unix make, add parallel to build script////* Fixed build break for shared_lib and cmpile warning////* Fix a compile warning////* test////* Revert the accidental push from another branch////This reverts commit 472029ba25d50f9508474c9eeceb3454cead7877.////* Add ability to track per operator types in reduced build config. (#6428)////* Add ability to generate configuration that includes required types for individual operators, to allow build size reduction based on that.//  - Add python bindings for ORT format models//    - Add script to update bindings and help info//  - Add parsing of ORT format models//  - Add ability to enable type reduction to config generation//  - Update build.py to only allow operator/type reduction via config//    - simpler to require config to be generated first//    - can't mix a type aware (ORT format model only) and non-type aware config as that may result in insufficient types being enabled//  - Add script to create reduced build config//  - Update CIs////* merge e2e with distributed pipeline (#6443)////merge e2e with distributed pipeline////* Fix test breaks in Windows ingestion pipeline (#6476)////* fix various build breaks with Windows build////* fix runtime errors loading libraries from system32////* add build_inbox check to winml_test_common////* use raw string////* cleanup////* fix dll load////Co-authored-by: Sheil Kumar <sheilk@microsoft.com>////* Speed up the Mac CI runs (#6483)////* expose learningmodelpixelrange property (#5877)////* Fix of support api version bug for [de]quantize (#6492)////* SDL fixes: add proper casts/format specifiers (#6446)////* SDL annotation fixes (#6448)////Co-authored-by: Ori Levari <orlevari@microsoft.com>////* [OpenVINO-EP] Remove support for OpenVINO 2020.2 (#6493)////* Removed OpenVINO 2020.2 support////* Updated documentation and build.py////* Removed unnecessary libraries from setup.py////* Support pad operator in quantization and quantized nhwc transformer. Fix Pad operator bug. (#6325)////Support pad operator in quantization tool.//Support pad operator in quantized nhwc transformer.//Fix pad() operator bug when pad input's inner(right) most axis value is zero for Edge and Reflect mode, it copied wrong value to the cells to be padded. Note the Constant mode will not trigger this bug, as Edge/Reflect need copy value from the already copied array while Constant mode only fill specified value.//Add more test cases to cover pad() operator bug fixed here.//Fix quantization tools uint8/int8 value overflow issue when quantize weights in python.////* Improve work distribution for Expand operator, and sharded LoopCounter configuration (#6454)////Description: This PR makes two changes identified while looking at a PGAN model.////First, it uses ThreadPool::TryParallelFor for the main parallel loops in the Expand operator. This lets the thread pool decide on the granularity at which to distribute work (unlike TrySimpleParallelFor). Profiling showed high costs when running ""simple"" loops with 4M iterations each of which copied only 4 bytes.////Second, it updates the sharded loop counter in the thread pool so that the number of shards is capped by the number of threads. This helps make the performance of any other high-contention ""simple"" loops more robust at low thread counts by letting each thread work on its own ""home"" shard for longer.////Motivation and Context////Profiling showed a PGAN model taking 2x+ longer with the non-OpenMP build. The root cause was that the OpenMP build uses simple static scheduling of loop iterations, while the non-OpenMP build uses dynamic scheduling. The combination of large numbers of tiny iterations is less significant with static scheduling --- although still desirable to avoid, given that each iteration incurs a std::function invocation.////* Update document of transformer optimization (#6487)////* nuphar test to avoid test data download to improve passing rate (#6467)////nuphar test to avoid test data download to improve passing rate////* Fuse cuda conv with activation (#6351)////* optimize cuda conv by fused activation////* remove needless print out////* exclude test from cpu////* handle status error from cudnn 8.x////* add reference to base class////* add hipify////* [CoreML EP] Add support for some activations/Transpose, move some shared helpers from NNAPI to shared space (#6498)////* Init change////* Move some helper from nnapi ep to shared////* Add transpose support////* Fix trt ci build break////* Refine transformers profiler output (#6502)////* output nodes in the original order; grouped by node name//* add document for profiler////* Update to match new test setup. (#6496)////* Update to match new test setup.////* Add Gemm(7) manually for now.//Will fix properly on Monday. It's used by mnist.ort as that is created by optimizing mnist.onnx to level 1 causing 2 nodes to be replaced by a Gemm and the op to be missing from the required list as that is created using the original onnx model.////* Enable dense sequence optimized version of Pytorch exported BERT-L on AMD GPU (#6504)////* Permit dense seq optimization on BERT-L pytorch export by enabling ReduceSumTraining, Equal, and NonZero on AMD////* enable Equal tests////* enable fast_matrix_reduction test case////* Optimize GatherGrad for AMD GPU (#6381)////* optimize gathergrad////* address comments////Co-authored-by: Weixing Zhang <wezhan@microsoft.com>////* add explicit barriers for buffer overread and overrwrite (#6484)////Co-authored-by: Ori Levari <orlevari@microsoft.com>////* fix sdl bugs for uninitialized variables and returns (#6450)////Co-authored-by: Ori Levari <orlevari@microsoft.com>////* handle hr error conditions (#6449)////Co-authored-by: Ori Levari <orlevari@microsoft.com>////* Dnnl training (#6045)////* Add ReluGrad and ConvGrad ops for the dnnl provider////* the mnist sample is updated to add the --use_dnnl option that//will cause the sample to use the dnnl execution provider for//nodes that exist in dnnl provider.////* Added the ability to find forward ops. Dnnl backward gradient//ops require the forward primitive description and workspace//from the forward operation.////* Enable specifying the execution provider for Gradient Checker Tests////* Prevent memory leak when running dnnl_provider in training mode////Prevent creating a SubgraphPrimitivePool when the code is built with the//ENABLE_TRAINING build flag. Instead create a SubgraphPrimitive directly.////The SubgraphPrimitivePool was causing a pool of SubgraphPrimitives to be//stashed in a map for reuse. Due to the way the Training Loop uses threads//the pool of SubgraphPrimitives were not being reuse instead a new pool of//SubgraphPrimitives being created each run. The old pool was not instantly//freed. This behavior could be a language error when using thread_local//memory.////Signed-off-by: George Nash <george.nash@intel.com>////* Added fixes to maxpoolgrad and memory leak.////Maxpoolgrad will now pass all unit tests.//With the conv and convgrad disabled for dnnl, mnist is able to train till 95%////Signed-off-by: Chethan Palangotu Keshava <chethan.palangotu.keshava@intel.com>////* Fixed misc issues when testing training code with dnnl provider////* fix conv_grad dnnl tests with dilation to run dnnl execution provider////* update mnist training sample to accept convolution type models////  convolution models require the input shape to be {1, 28, 28}//  instead of the flat {728} image that is used for the gemm models////  this will enable models that require the different shape by adding// `--model_type conv` to the command line when running the mnist sample.// (while testing a workaround was used see #4762)////* Disable weight caching in dnnl conv operator when using training////  When training we can not use cached weights because the weight//  will be updated each run. This re-enables dnnl Conv and ConvGrad Ops.//  The weight caching was the source of the error from Conv when training.////* Fix issues found when building grad ops on Linux//  * The dnnl_convgrad code was over using the scope operator//    causing a compilation problem.//  * The dnnl_maxpoolgrad code had a logic error that is was//    comparing with the source description when it should have//    been comparing with the destination despription.////* Update BUILD.md so it shows DNNL for training//  * Updated the table of contents. Since the same providers//    are listed twice. Once for Infrance and again for Training//    an HTML anchor was added to distinguish the second header//    from the first for the TOC.////* Fix build failure when not using --enable-training build option////* reorganize the gradient operators so they are grouped together////* Fix issues found when running onnx_backend_test_series.py////* Pooling code only supports 2 outputs when built with --enable-training////* Address code review feedback//  * class member variables end in underscore_//  * use dst instead of dist to match pattern use elsewhere in DNNL code.////* Remove workaround that was introduced to handle problems running//  convolution based training models. See issue #4762////Signed-off-by: George Nash <george.nash@intel.com>////* Isolate training code and code cleanup////* Do not build if dnnl_gpu_runtime if enable_training is set training code//  does not support dnnl_gpu_runtime yet.//* Isolated Training code inside ifdefs so that they wont affect//  project if built without training enabled//* Inadvertant changes in whitespace were removed to make code review simpler//* Undid some code reordering that was not needed//* comments added to closing #endif statments to simplify reading complex ifdefs//* Modified the GetPrimitiveDesc functions to return shared_ptr instead of raw//  pointer. This matches what was done in Pool code and is safer memory code.////Signed-off-by: George Nash <george.nash@intel.com>////* Address code review issues////- whitespace changes caused by running clang-format on the code//- Several spelling errors fixed//- Removed/changed some ifdefs to improve readability//- other misc. changes in responce to code review.////Signed-off-by: George Nash <george.nash@intel.com>////* Code changes to address code review////- Simplify iteration code using `auto` keyword//- remove C style cast that was not needed//- remove instance variable that was not needed [relugrad.h]//- added the execution providers to `ComputeGradientErrorInternal()`//  and `ComputeTheoreticalJacobianTranspose()` instead of using//  a pointer to an instance varaible [gradient_checker.h/.cc]////Signed-off-by: George Nash <george.nash@intel.com>////* Combined the default gradient ops test and dnnl gradient ops test for ConvGrad and MaxPoolGrad into one function with the help of a helper function.//This will reduce repeated code.//Signed-off-by: Palangotu Keshava, Chethan's avatarChethan Palangotu Keshava <chethan.palangotu.keshava@intel.com>////* Replaced the stack used by convgrad to vector so that the vector(used as stack) can be easily cleared everytime the graph is created.//This will prevent memory leak from convolution kernels being pushed constantly onto the stack.//Signed-off-by: chethan.palangotu.keshava@intel.com////* Code clean up and formating updates//// - Removed empty else statment// - updated indentation of code that was causing double curly brackets to look unususal// - Changed check for NumDimensions to Size in Relu and ReluGrad error checking code.// - isolated training code////Signed-off-by: George Nash <george.nash@intel.com>////* Restore inadvertantly removed ConvGrad tests////When combining the DNNL and CPU version of the ConvGrad//tests two test were inadvertantly excluded.  This adds//back the Conv3d and Conv3d with strides test cases.////Signed-off-by: George Nash <george.nash@intel.com>////* Add validation to ConvGrad////This validates the dimensions of the ConvGrad match the//passed in Convolution forward primitive description.////The current code for DNNL ConvGrad makes the assumption that the ConvGrad//nodes will be visited in the reverse order from the corresponding Conv nodes////The added validation will return an error if this assumption is not true.////Signed-off-by: George Nash <george.nash@intel.com>////* Do not create new execution providers in provider_test_utils////This removes the code that generated new execution providers in the//OpTester::Run function. This was added because the std::move was//leaving the `entry` value empty so subsequent calls would cause a//segfault.////Problem is this potentially changed the execution_provider because it//would create the default provider dropping any custom arguments.////When the now removed code was originally added the std::move was causing//crashes when the GradientChecker unit tests were run.  However, it is no//longer causing problems even with the code removed.////Signed-off-by: George Nash <george.nash@intel.com>////* Change the forward conv stack to a forward conv map////This changes how the forward conv kernel is mapped to the bwd ConvGrad//kernel the problematic stack is no longer used.////The convolution stack made the assumption that the corresponding//ConvGrad operator would be visited in reverse order of the forward//Conv operators.  This was always problematic and was unlikely to//work for inception models.////Important changes://- The weight_name is added to the ConvGrad dnnl_node making it//  possible to use the weight_name as a lookup key to find the//  Conv forward Kernel//- the `std::vector fwd_conv_stack_` has been replaced with a//  `std::map fwd_conv_kernel_map_`//- Although it is not needed lock_guards were added when writing//  to and reading from the fwd_conv_kernel_map_ as well as the//  fwd_kernel_map_. These should always be accessed by a single//  thread when preparing the dnnl subgraphs so the guard should not//  be needed but its added just in case.//- Updated the comments ConvGrad.h code to no longer mention the//  stack. The error check is not removed. It will be good to verify//  there are no errors as we continue to test against more models.////Signed-off-by: George Nash <george.nash@intel.com>////Co-authored-by: Chethan Palangotu Keshava <chethan.palangotu.keshava@intel.com>//Co-authored-by: unknown <63478620+jeyblu@users.noreply.github.com>////* Lochi/refactor yolov3 quantization (#6290)////* Refactor the code and move data reader, preprocessing, evaluation to//E2E_example_mode////* Refactor the code.////Move data reader, preprocessing, evaluation to model specific example//under E2E_example_mode////* refactor code////* Move yolov3 example to specific folder and add additional pre/post//processing////* Print a warning message for using newer c_api header on old binary (#6507)////* Fix issues with ArmNN build setup (#6495)////* ArmNN build fixes//* Update BUILD.md to document that the ACL paths must be specified to build ArmNN//* Fix CUDA build error. We don't setup the link libraries correctly/consistently so improve that.////* Fix Windows CI builds by updating test scripts to work with numpy 1.20. (#6518)////* Update onnxruntime_test_python.py to work with numpy 1.20.////Some aliases are deprecated in favor of the built-in python types. See https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations////np.array with bytes for entries and dtype of np.void no longer automatically pads. Change a test to adjust for that.////* Fix another test script////* Fix ORTModule branch for orttraining-* pipelines////* Update pytorch nightly version dependency////Co-authored-by: Edward Chen <18449977+edgchen1@users.noreply.github.com>//Co-authored-by: George Wu <jywu@microsoft.com>//Co-authored-by: Cecilia Liu <ziyue.liu7@gmail.com>//Co-authored-by: Ryan Hill <38674843+RyanUnderhill@users.noreply.github.com>//Co-authored-by: George Nash <george.nash@intel.com>//Co-authored-by: Guoyu Wang <62914304+gwang-msft@users.noreply.github.com>//Co-authored-by: Yateng Hong <toothache9010@gmail.com>//Co-authored-by: stevenlix <38092805+stevenlix@users.noreply.github.com>//Co-authored-by: Derek Murray <Derek.Murray@microsoft.com>//Co-authored-by: ashbhandare <ash.bhandare@gmail.com>//Co-authored-by: Scott McKay <skottmckay@gmail.com>//Co-authored-by: Changming Sun <chasun@microsoft.com>//Co-authored-by: Tracy Sharpe <42477615+tracysh@users.noreply.github.com>//Co-authored-by: Juliana Franco <jufranc@microsoft.com>//Co-authored-by: Pranav Sharma <prs@microsoft.com>//Co-authored-by: Tixxx <tix@microsoft.com>//Co-authored-by: Jay Rodge <jayrodge@live.com>//Co-authored-by: Du Li <duli1@microsoft.com>//Co-authored-by: Du Li <duli@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: Yufeng Li <liyufeng1987@gmail.com>//Co-authored-by: baijumeswani <bmeswani@microsoft.com>//Co-authored-by: Sergii Dymchenko <sedymche@microsoft.com>//Co-authored-by: jingyanwangms <47403504+jingyanwangms@users.noreply.github.com>//Co-authored-by: satyajandhyala <satya.k.jandhyala@gmail.com>//Co-authored-by: S. Manohar Karlapalem <manohar.karlapalem@intel.com>//Co-authored-by: Weixing Zhang <weixingzhang@users.noreply.github.com>//Co-authored-by: Suffian Khan <sukha@microsoft.com>//Co-authored-by: Olivia Jain <oljain@microsoft.com>//Co-authored-by: Chi Lo <54722500+chilo-ms@users.noreply.github.com>//Co-authored-by: Hariharan Seshadri <shariharan91@gmail.com>//Co-authored-by: Ryan Lai <rylai@microsoft.com>//Co-authored-by: Jesse Benson <jesseb@microsoft.com>//Co-authored-by: sfatimar <64512376+sfatimar@users.noreply.github.com>//Co-authored-by: suryasidd <surya.siddharth.pemmaraju@intel.com>//Co-authored-by: sfatimar <sahar.fatima@intel/com>//Co-authored-by: MaajidKhan <n.maajidkhan@gmail.com>//Co-authored-by: mohdansx <mohdx.ansari@intel.com>//Co-authored-by: Xavier Dupré <xadupre@users.noreply.github.com>//Co-authored-by: Michael Goin <mgoin@vols.utk.edu>//Co-authored-by: Michael Giba <michaelgiba@gmail.com>//Co-authored-by: William Tambellini <wtambellini@sdl.com>//Co-authored-by: Hector Li <hecli@microsoft.com>//Co-authored-by: Aishwarya <aibhanda@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: liqunfu <liqfu@microsoft.com>//Co-authored-by: liqun <liqun@OrtTrainingDev4.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: pengwa <pengwa@microsoft.com>//Co-authored-by: Tang, Cheng <souptc@gmail.com>//Co-authored-by: Cheng Tang <chenta@microsoft.com>//Co-authored-by: Tianlei Wu <tlwu@microsoft.com>//Co-authored-by: Ye Wang <52801275+wangyems@users.noreply.github.com>//Co-authored-by: Chun-Wei Chen <jacky82226@gmail.com>//Co-authored-by: Vincent Wang <wangwchpku@outlook.com>//Co-authored-by: Vincent Wang <weicwang@microsoft.com>//Co-authored-by: Luyao Ren <375833274@qq.com>//Co-authored-by: Zhang Lei <zhang.huanning@hotmail.com>//Co-authored-by: Tim Harris <tiharr@microsoft.com>//Co-authored-by: Ashwini Khade <askhade@microsoft.com>//Co-authored-by: Dmitri Smirnov <yuslepukhin@users.noreply.github.com>//Co-authored-by: Alberto Magni <49027342+alberto-magni@users.noreply.github.com>//Co-authored-by: Wei-Sheng Chin <wschin@outlook.com>//Co-authored-by: wezuo <49965641+wezuo@users.noreply.github.com>//Co-authored-by: Jesse Benson <benson.jesse@gmail.com>//Co-authored-by: Wei Zuo <wezuo@OrtTrainingDev3.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: wezuo <wezuo@az-eus-v100-32gb-5-worker-mgtbby.eastus.cloudapp.azure.com>//Co-authored-by: wezuo <wezuo@az-eus-v100-32gb-5-worker-yclzsf.eastus.cloudapp.azure.com>//Co-authored-by: Wenbing Li <10278425+wenbingl@users.noreply.github.com>//Co-authored-by: Martin Man <supermt@gmail.com>//Co-authored-by: M. Zeeshan Siddiqui <mzs@microsoft.com>//Co-authored-by: Ori Levari <ori.levari@microsoft.com>//Co-authored-by: Ori Levari <orlevari@microsoft.com>//Co-authored-by: Ubuntu <OrtTrainingDev3@OrtTrainingDev3.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: Sherlock Huang <bahuang@OrtTrainingDev3.af05slrtruoetgaxwwjv5nsq5e.px.internal.cloudapp.net>//Co-authored-by: Sheil Kumar <smk2007@gmail.com>//Co-authored-by: Sheil Kumar <sheilk@microsoft.com>//Co-authored-by: Ryota Tomioka <ryoto@microsoft.com>//Co-authored-by: Adam Pocock <adam.pocock@oracle.com>//Co-authored-by: Yulong Wang <f.s@qq.com>//Co-authored-by: Faith Xu <faxu@microsoft.com>//Co-authored-by: Xiang Zhang <xianz@microsoft.com>//Co-authored-by: suryasidd <48925384+suryasidd@users.noreply.github.com>//Co-authored-by: RandySheriffH <48490400+RandySheriffH@users.noreply.github.com>//Co-authored-by: Weixing Zhang <wezhan@microsoft.com>//Co-authored-by: Chethan Palangotu Keshava <chethan.palangotu.keshava@intel.com>//Co-authored-by: unknown <63478620+jeyblu@users.noreply.github.com>",https://github.com/microsoft/onnxruntime/commit/8a890ddfd749a2f46609f8e234f192780bb41356,156939672,microsoft/onnxruntime,False,False
d06af35e34cb355b6e38599638169fc412568dce,"Refactor to support unresolved elements. This requires changing all calls from GetReferenced to GetReferencedRelationshipInstances for Peer and Hierarchical relationships. With methods now returning unresolved elements, a new Reference sub class for each Model type is defined. The reference sub types adapts a ModelRelationshipInstance instead of a TSQLObject. Adapting a ModelRelationshipInstance instead of a TSQLObject allows the name of referenced elements to be exposed even if the element is unresolved. It also allows exposing the metadata on relationships (Such as Ascending on the Index.Columns relationship)./For each relationship that has metadata, a new sub type is defined with the metadata properties. This results in the Index.Columns relationship returning an IEnumerable<IndexColumnsReference> where IndexColumnsReference derives from TSQLColumnReference which in-turn derives from TSQLColum./Metadata properties on TSQLObjecs are now exposed. One example of this is TSQLColumn now exposes a ColumnType property which defines if it is a Column, ComputedColumn or ColumnSet./NOTE: In order to facilitate unresolved references, a few edge cases arose. For relationships that returned marker interfaces like ISqlObjectAuthorizer, there was no concrete type known at generation time to instantiate. To work around this issue, a new optional attribute was added to the modelmetadata.xml: UnresolvedReturnType. The UnresolvedReturnType attribute defines the type to instantiate when an unresolved element is found so the return type will still implement the type defined in the ReturnType attribute. This pattern is a little unconventional, however, to enforce the strongly typed returns values of relationships these “Unresolved” types needed to be created to bridge the gap between the strongly typed API and the unresolved nature of the model.",https://github.com/microsoft/DACExtensions/commit/d06af35e34cb355b6e38599638169fc412568dce,30130401,microsoft/DACExtensions,False,False
12ade69c1eb9958b13374edf5ef742ea20ccffde,"KVM: PPC: Book3S HV: XIVE: Ensure VP isn't already in use//Connecting a vCPU to a XIVE KVM device means establishing a 1:1/association between a vCPU id and the offset (VP id) of a VP/structure within a fixed size block of VPs. We currently try to/enforce the 1:1 relationship by checking that a vCPU with the/same id isn't already connected. This is good but unfortunately/not enough because we don't map VP ids to raw vCPU ids but to/packed vCPU ids, and the packing function kvmppc_pack_vcpu_id()/isn't bijective by design. We got away with it because QEMU passes/vCPU ids that fit well in the packing pattern. But nothing prevents/userspace to come up with a forged vCPU id resulting in a packed id/collision which causes the KVM device to associate two vCPUs to the/same VP. This greatly confuses the irq layer and ultimately crashes/the kernel, as shown below.//Example: a guest with 1 guest thread per core, a core stride of/8 and 300 vCPUs has vCPU ids 0,8,16...2392. If QEMU is patched to/inject at some point an invalid vCPU id 348, which is the packed/version of itself and 2392, we get://genirq: Flags mismatch irq 199. 00010000 (kvm-2-2392) vs. 00010000 (kvm-2-348)/CPU: 24 PID: 88176 Comm: qemu-system-ppc Not tainted 5.3.0-xive-nr-servers-5.3-gku+ #38/Call Trace:/[c000003f7f9937e0] [c000000000c0110c] dump_stack+0xb0/0xf4 (unreliable)/[c000003f7f993820] [c0000000001cb480] __setup_irq+0xa70/0xad0/[c000003f7f9938d0] [c0000000001cb75c] request_threaded_irq+0x13c/0x260/[c000003f7f993940] [c00800000d44e7ac] kvmppc_xive_attach_escalation+0x104/0x270 [kvm]/[c000003f7f9939d0] [c00800000d45013c] kvmppc_xive_connect_vcpu+0x424/0x620 [kvm]/[c000003f7f993ac0] [c00800000d444428] kvm_arch_vcpu_ioctl+0x260/0x448 [kvm]/[c000003f7f993b90] [c00800000d43593c] kvm_vcpu_ioctl+0x154/0x7c8 [kvm]/[c000003f7f993d00] [c0000000004840f0] do_vfs_ioctl+0xe0/0xc30/[c000003f7f993db0] [c000000000484d44] ksys_ioctl+0x104/0x120/[c000003f7f993e00] [c000000000484d88] sys_ioctl+0x28/0x80/[c000003f7f993e20] [c00000000000b278] system_call+0x5c/0x68/xive-kvm: Failed to request escalation interrupt for queue 0 of VCPU 2392/------------[ cut here ]------------/remove_proc_entry: removing non-empty directory 'irq/199', leaking at least 'kvm-2-348'/WARNING: CPU: 24 PID: 88176 at /home/greg/Work/linux/kernel-kvm-ppc/fs/proc/generic.c:684 remove_proc_entry+0x1ec/0x200/Modules linked in: kvm_hv kvm dm_mod vhost_net vhost tap xt_CHECKSUM iptable_mangle xt_MASQUERADE iptable_nat nf_nat xt_conntrack nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 ipt_REJECT nf_reject_ipv4 tun bridge stp llc ebtable_filter ebtables ip6table_filter ip6_tables iptable_filter squashfs loop fuse i2c_dev sg ofpart ocxl powernv_flash at24 xts mtd uio_pdrv_genirq vmx_crypto opal_prd ipmi_powernv uio ipmi_devintf ipmi_msghandler ibmpowernv ib_iser rdma_cm iw_cm ib_cm ib_core iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi ip_tables ext4 mbcache jbd2 raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor xor async_tx raid6_pq libcrc32c raid1 raid0 linear sd_mod ast i2c_algo_bit drm_vram_helper ttm drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci libata tg3 drm_panel_orientation_quirks [last unloaded: kvm]/CPU: 24 PID: 88176 Comm: qemu-system-ppc Not tainted 5.3.0-xive-nr-servers-5.3-gku+ #38/NIP:  c00000000053b0cc LR: c00000000053b0c8 CTR: c0000000000ba3b0/REGS: c000003f7f9934b0 TRAP: 0700   Not tainted  (5.3.0-xive-nr-servers-5.3-gku+)/MSR:  9000000000029033 <SF,HV,EE,ME,IR,DR,RI,LE>  CR: 48228222  XER: 20040000/CFAR: c000000000131a50 IRQMASK: 0/GPR00: c00000000053b0c8 c000003f7f993740 c0000000015ec500 0000000000000057/GPR04: 0000000000000001 0000000000000000 000049fb98484262 0000000000001bcf/GPR08: 0000000000000007 0000000000000007 0000000000000001 9000000000001033/GPR12: 0000000000008000 c000003ffffeb800 0000000000000000 000000012f4ce5a1/GPR16: 000000012ef5a0c8 0000000000000000 000000012f113bb0 0000000000000000/GPR20: 000000012f45d918 c000003f863758b0 c000003f86375870 0000000000000006/GPR24: c000003f86375a30 0000000000000007 c0002039373d9020 c0000000014c4a48/GPR28: 0000000000000001 c000003fe62a4f6b c00020394b2e9fab c000003fe62a4ec0/NIP [c00000000053b0cc] remove_proc_entry+0x1ec/0x200/LR [c00000000053b0c8] remove_proc_entry+0x1e8/0x200/Call Trace:/[c000003f7f993740] [c00000000053b0c8] remove_proc_entry+0x1e8/0x200 (unreliable)/[c000003f7f9937e0] [c0000000001d3654] unregister_irq_proc+0x114/0x150/[c000003f7f993880] [c0000000001c6284] free_desc+0x54/0xb0/[c000003f7f9938c0] [c0000000001c65ec] irq_free_descs+0xac/0x100/[c000003f7f993910] [c0000000001d1ff8] irq_dispose_mapping+0x68/0x80/[c000003f7f993940] [c00800000d44e8a4] kvmppc_xive_attach_escalation+0x1fc/0x270 [kvm]/[c000003f7f9939d0] [c00800000d45013c] kvmppc_xive_connect_vcpu+0x424/0x620 [kvm]/[c000003f7f993ac0] [c00800000d444428] kvm_arch_vcpu_ioctl+0x260/0x448 [kvm]/[c000003f7f993b90] [c00800000d43593c] kvm_vcpu_ioctl+0x154/0x7c8 [kvm]/[c000003f7f993d00] [c0000000004840f0] do_vfs_ioctl+0xe0/0xc30/[c000003f7f993db0] [c000000000484d44] ksys_ioctl+0x104/0x120/[c000003f7f993e00] [c000000000484d88] sys_ioctl+0x28/0x80/[c000003f7f993e20] [c00000000000b278] system_call+0x5c/0x68/Instruction dump:/2c230000 41820008 3923ff78 e8e900a0 3c82ff69 3c62ff8d 7fa6eb78 7fc5f378/3884f080 3863b948 4bbf6925 60000000 <0fe00000> 4bffff7c fba10088 4bbf6e41/---[ end trace b925b67a74a1d8d1 ]---/BUG: Kernel NULL pointer dereference at 0x00000010/Faulting instruction address: 0xc00800000d44fc04/Oops: Kernel access of bad area, sig: 11 [#1]/LE PAGE_SIZE=64K MMU=Radix MMU=Hash SMP NR_CPUS=2048 NUMA PowerNV/Modules linked in: kvm_hv kvm dm_mod vhost_net vhost tap xt_CHECKSUM iptable_mangle xt_MASQUERADE iptable_nat nf_nat xt_conntrack nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 ipt_REJECT nf_reject_ipv4 tun bridge stp llc ebtable_filter ebtables ip6table_filter ip6_tables iptable_filter squashfs loop fuse i2c_dev sg ofpart ocxl powernv_flash at24 xts mtd uio_pdrv_genirq vmx_crypto opal_prd ipmi_powernv uio ipmi_devintf ipmi_msghandler ibmpowernv ib_iser rdma_cm iw_cm ib_cm ib_core iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi ip_tables ext4 mbcache jbd2 raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor xor async_tx raid6_pq libcrc32c raid1 raid0 linear sd_mod ast i2c_algo_bit drm_vram_helper ttm drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci libata tg3 drm_panel_orientation_quirks [last unloaded: kvm]/CPU: 24 PID: 88176 Comm: qemu-system-ppc Tainted: G        W         5.3.0-xive-nr-servers-5.3-gku+ #38/NIP:  c00800000d44fc04 LR: c00800000d44fc00 CTR: c0000000001cd970/REGS: c000003f7f9938e0 TRAP: 0300   Tainted: G        W          (5.3.0-xive-nr-servers-5.3-gku+)/MSR:  9000000000009033 <SF,HV,EE,ME,IR,DR,RI,LE>  CR: 24228882  XER: 20040000/CFAR: c0000000001cd9ac DAR: 0000000000000010 DSISR: 40000000 IRQMASK: 0/GPR00: c00800000d44fc00 c000003f7f993b70 c00800000d468300 0000000000000000/GPR04: 00000000000000c7 0000000000000000 0000000000000000 c000003ffacd06d8/GPR08: 0000000000000000 c000003ffacd0738 0000000000000000 fffffffffffffffd/GPR12: 0000000000000040 c000003ffffeb800 0000000000000000 000000012f4ce5a1/GPR16: 000000012ef5a0c8 0000000000000000 000000012f113bb0 0000000000000000/GPR20: 000000012f45d918 00007ffffe0d9a80 000000012f4f5df0 000000012ef8c9f8/GPR24: 0000000000000001 0000000000000000 c000003fe4501ed0 c000003f8b1d0000/GPR28: c0000033314689c0 c000003fe4501c00 c000003fe4501e70 c000003fe4501e90/NIP [c00800000d44fc04] kvmppc_xive_cleanup_vcpu+0xfc/0x210 [kvm]/LR [c00800000d44fc00] kvmppc_xive_cleanup_vcpu+0xf8/0x210 [kvm]/Call Trace:/[c000003f7f993b70] [c00800000d44fc00] kvmppc_xive_cleanup_vcpu+0xf8/0x210 [kvm] (unreliable)/[c000003f7f993bd0] [c00800000d450bd4] kvmppc_xive_release+0xdc/0x1b0 [kvm]/[c000003f7f993c30] [c00800000d436a98] kvm_device_release+0xb0/0x110 [kvm]/[c000003f7f993c70] [c00000000046730c] __fput+0xec/0x320/[c000003f7f993cd0] [c000000000164ae0] task_work_run+0x150/0x1c0/[c000003f7f993d30] [c000000000025034] do_notify_resume+0x304/0x440/[c000003f7f993e20] [c00000000000dcc4] ret_from_except_lite+0x70/0x74/Instruction dump:/3bff0008 7fbfd040 419e0054 847e0004 2fa30000 419effec e93d0000 8929203c/2f890000 419effb8 4800821d e8410018 <e9230010> e9490008 9b2a0039 7c0004ac/---[ end trace b925b67a74a1d8d2 ]---//Kernel panic - not syncing: Fatal exception//This affects both XIVE and XICS-on-XIVE devices since the beginning.//Check the VP id instead of the vCPU id when a new vCPU is connected./The allocation of the XIVE CPU structure in kvmppc_xive_connect_vcpu()/is moved after the check to avoid the need for rollback.//Cc: stable@vger.kernel.org # v4.12+/Signed-off-by: Greg Kurz <groug@kaod.org>/Reviewed-by: Cédric Le Goater <clg@kaod.org>/Signed-off-by: Paul Mackerras <paulus@ozlabs.org>",https://github.com/microsoft/WSL2-Linux-Kernel/commit/12ade69c1eb9958b13374edf5ef742ea20ccffde,187922067,microsoft/WSL2-Linux-Kernel,False,False
